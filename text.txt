
~/src/InferenceProfiler
❯ find . -type f -exec cat {} +
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="ALL" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="1cbe9042-a31b-4df2-8a57-8e5c1471d107" name="Changes" comment="" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="GOROOT" url="file://$USER_HOME$/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.25.5.linux-amd64" />
  <component name="ProjectColorInfo">{
  &quot;associatedIndex&quot;: 3
}</component>
  <component name="ProjectId" id="37ITsuFaVFIlqnYnVD1dlebx8c5" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">{
  &quot;keyToString&quot;: {
    &quot;ModuleVcsDetector.initialDetectionPerformed&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.GoLinterPluginOnboardingV2&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.GoLinterPluginStorageMigration&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.go.formatter.settings.were.checked&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.go.modules.go.list.on.any.changes.was.set&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.typescript.service.memoryLimit.init&quot;: &quot;true&quot;,
    &quot;com.intellij.ml.llm.matterhorn.ej.ui.settings.DefaultModelSelectionForGA.v1&quot;: &quot;true&quot;,
    &quot;go.sdk.automatically.set&quot;: &quot;true&quot;,
    &quot;last_opened_file_path&quot;: &quot;/home/austin/src/InferenceProfiler&quot;,
    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
    &quot;settings.editor.selected.configurable&quot;: &quot;settings.sync&quot;,
    &quot;to.speed.mode.migration.done&quot;: &quot;true&quot;
  }
}</component>
  <component name="RdControllerToolWindowsLayoutState" isNewUi="true">
    <layout>
      <window_info id="Bookmarks" side_tool="true" />
      <window_info id="Merge Requests" />
      <window_info id="Backup and Sync History" />
      <window_info id="aws.toolkit.explorer" side_tool="true" />
      <window_info id="Pull Requests" />
      <window_info id="Learn" show_stripe_button="false" />
      <window_info id="R_Remote_Host" side_tool="true" />
      <window_info active="true" content_ui="combo" id="Project" order="0" visible="true" weight="0.26765046" />
      <window_info id="Commit" order="1" weight="0.25" />
      <window_info id="Structure" order="2" side_tool="true" weight="0.25" />
      <window_info anchor="bottom" id="R_Jobs" />
      <window_info anchor="bottom" id="Database Changes" />
      <window_info anchor="bottom" id="TypeScript" />
      <window_info anchor="bottom" id="Educational.CheckDetails" />
      <window_info anchor="bottom" id="aws.sqs" />
      <window_info anchor="bottom" id="aws.cloudformation" />
      <window_info anchor="bottom" id="Python Packages" />
      <window_info anchor="bottom" id="R_Console" />
      <window_info anchor="bottom" id="TODO" />
      <window_info anchor="bottom" id="File Transfer" />
      <window_info anchor="bottom" id="PythonProcessOutput" />
      <window_info anchor="bottom" id="aws.cloudwatchlogs" />
      <window_info anchor="bottom" id="Version Control" order="0" />
      <window_info anchor="bottom" id="Problems" order="1" />
      <window_info anchor="bottom" id="Problems View" order="2" />
      <window_info anchor="bottom" id="Terminal" order="3" />
      <window_info anchor="bottom" id="Services" order="4" />
      <window_info anchor="bottom" id="Run" order="5" weight="0.32979703" />
      <window_info anchor="bottom" id="Find" order="6" weight="0.32979703" />
      <window_info anchor="right" id="PR AI Assistant" />
      <window_info anchor="right" id="Endpoints" />
      <window_info anchor="right" id="Remote Host" />
      <window_info anchor="right" id="make" side_tool="true" />
      <window_info anchor="right" id="R_Tools" />
      <window_info anchor="right" id="BigDataToolWindow" />
      <window_info anchor="right" id="Coverage" side_tool="true" />
      <window_info anchor="right" id="Python Console" />
      <window_info anchor="right" content_ui="combo" id="Notifications" order="0" weight="0.25" />
      <window_info anchor="right" id="AIAssistant" order="1" weight="0.25" />
      <window_info anchor="right" id="Database" order="2" weight="0.25" />
      <window_info anchor="right" id="Gradle" order="3" weight="0.25" />
      <window_info anchor="right" id="Maven" order="4" weight="0.25" />
      <window_info anchor="right" id="ElectroJunToolWindow" order="5" />
    </layout>
  </component>
  <component name="RecentsManager">
    <key name="CopyFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$" />
    </key>
    <key name="MoveFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$/utils" />
      <recent name="$PROJECT_DIR$/collectors" />
    </key>
  </component>
  <component name="RunAnythingCache">
    <option name="myCommands">
      <command value="go mod init" />
      <command value="go mod init InferenceProfiler" />
    </option>
  </component>
  <component name="SharedIndexes">
    <attachedChunks>
      <set>
        <option value="bundled-gosdk-72a9cf600ed8-448e06e64ec5-org.jetbrains.plugins.go.sharedIndexes.bundled-GO-253.28294.337" />
      </set>
    </attachedChunks>
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="1cbe9042-a31b-4df2-8a57-8e5c1471d107" name="Changes" comment="" />
      <created>1766589796003</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1766589796003</updated>
    </task>
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
</project># Default ignored files
/shelf/
/workspace.xml
# Ignored default folder with query files
/queries/
# Datasource local storage ignored files
/dataSources/
/dataSources.local.xml
# Editor-based HTTP Client requests
/httpRequests/
<?xml version="1.0" encoding="UTF-8"?>
<module type="WEB_MODULE" version="4">
  <component name="Go" enabled="true" />
  <component name="NewModuleRootManager">
    <content url="file://$MODULE_DIR$" />
    <orderEntry type="inheritedJdk" />
    <orderEntry type="sourceFolder" forTests="false" />
  </component>
</module><?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ProjectModuleManager">
    <modules>
      <module fileurl="file://$PROJECT_DIR$/.idea/InferenceProfiler.iml" filepath="$PROJECT_DIR$/.idea/InferenceProfiler.iml" />
    </modules>
  </component>
</project><?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="GoImports">
    <option name="excludedPackages">
      <array>
        <option value="github.com/pkg/errors" />
        <option value="golang.org/x/net/context" />
      </array>
    </option>
  </component>
</project><?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="accountSettings">
    <option name="activeProfile" value="profile:default" />
    <option name="activeRegion" value="us-east-2" />
    <option name="recentlyUsedProfiles">
      <list>
        <option value="profile:default" />
      </list>
    </option>
    <option name="recentlyUsedRegions">
      <list>
        <option value="us-east-2" />
      </list>
    </option>
  </component>
</project>// inference-profiler collects system resource metrics and exports to JSON/CSV/Parquet.
//
// Usage:
//
//      inference-profiler [flags] [-- command args...]
//
// Flags:
//
//      -o, --output DIR     Output directory (default: ./profiler-output)
//      -t, --interval MS    Sampling interval in milliseconds (default: 1000)
//      -f, --format FMT     Export format: csv, tsv, parquet (default: parquet)
//      -p, --processes      Enable per-process metrics (expensive)
//      -h, --help           Show help
//
// If a command is provided after --, the profiler runs until that command exits.
// Otherwise, it runs until interrupted (Ctrl+C).
package main

import (
        "crypto/rand"
        "flag"
        "fmt"
        "log"
        "os"
        "os/exec"
        "os/signal"
        "syscall"
        "time"
)

// newUUID generates a random UUID v4.
func newUUID() string {
        var b [16]byte
        rand.Read(b[:])
        b[6] = (b[6] & 0x0f) | 0x40 // version 4
        b[8] = (b[8] & 0x3f) | 0x80 // variant
        return fmt.Sprintf("%08x-%04x-%04x-%04x-%012x",
                b[0:4], b[4:6], b[6:8], b[8:10], b[10:16])
}

func main() {
        // Flags
        outputDir := flag.String("o", "./profiler-output", "Output directory")
        interval := flag.Int("t", 1000, "Sampling interval (ms)")
        format := flag.String("f", "parquet", "Export format: csv, tsv, parquet")
        processes := flag.Bool("p", false, "Collect per-process metrics")
        flag.Parse()

        // UUID for session
        sessionUUID := newUUID()

        log.Printf("Session UUID: %s", sessionUUID)
        log.Printf("Output Dir:   %s", *outputDir)
        log.Printf("Interval:     %dms", *interval)
        log.Printf("Format:       %s", *format)

        // Initialize
        mgr := collector.NewManager(*processes)
        defer mgr.Close()

        exp := exporter.New(*outputDir, sessionUUID)

        // Save static info
        log.Println("Capturing static hardware info...")
        static := mgr.GetStatic(sessionUUID)
        if err := exp.SaveStatic(static); err != nil {
                log.Printf("Warning: failed to save static info: %v", err)
        }

        // Optional subprocess
        var proc *exec.Cmd
        args := flag.Args()
        if len(args) > 0 {
                log.Printf("Starting subprocess: %v", args)
                proc = exec.Command(args[0], args[1:]...)
                proc.Stdout = os.Stdout
                proc.Stderr = os.Stderr
                if err := proc.Start(); err != nil {
                        log.Fatalf("Failed to start command: %v", err)
                }
        }

        // Signal handling
        sigCh := make(chan os.Signal, 1)
        signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)

        // Profiling loop
        log.Println("Profiling started. Press Ctrl+C to stop.")
        ticker := time.NewTicker(time.Duration(*interval) * time.Millisecond)
        defer ticker.Stop()

        running := true
        for running {
                select {
                case <-ticker.C:
                        snapshot := mgr.Collect()
                        if err := exp.SaveSnapshot(snapshot); err != nil {
                                log.Printf("Warning: failed to save snapshot: %v", err)
                        }

                        // Check subprocess
                        if proc != nil {
                                if proc.ProcessState != nil && proc.ProcessState.Exited() {
                                        log.Printf("Subprocess finished with exit code %d", proc.ProcessState.ExitCode())
                                        running = false
                                }
                        }

                case sig := <-sigCh:
                        log.Printf("Signal %v received. Stopping...", sig)
                        running = false
                }
        }

        // Cleanup
        log.Println("Shutting down...")

        if proc != nil && proc.Process != nil {
                proc.Process.Signal(syscall.SIGTERM)
                done := make(chan error, 1)
                go func() { done <- proc.Wait() }()

                select {
                case <-done:
                case <-time.After(2 * time.Second):
                        proc.Process.Kill()
                }
        }

        log.Printf("Converting session data to %s...", *format)
        if err := exp.ProcessSession(*format); err != nil {
                log.Printf("Error processing session: %v", err)
        }

        log.Println("Done.")
}
#!/bin/bash
# generate_testdata.sh - Generate sample procfs/sysfs files for testing.
#
# Creates realistic mock data for all files the profiler reads.
# Output goes to testdata/ directory, mirroring real system paths.

set -euo pipefail

OUTDIR="${1:-testdata}"

echo "Generating test data in $OUTDIR..."

# Create directory structure
mkdir -p "$OUTDIR"/{proc,sys/fs/cgroup,sys/devices/system/cpu,sys/class/dmi/id}
mkdir -p "$OUTDIR"/proc/{1,42,1337,net,self}
mkdir -p "$OUTDIR"/sys/fs/cgroup/{cpuacct,memory,blkio}
mkdir -p "$OUTDIR"/sys/devices/system/cpu/{cpu0,cpu1,cpu2,cpu3}/{cache/index0,cache/index1,cache/index2,cache/index3,cpufreq}

# =============================================================================
# /proc/stat - CPU statistics
# =============================================================================
cat > "$OUTDIR/proc/stat" << 'EOF'
cpu  10132153 290696 3084719 46828483 16683 0 25195 0 0 0
cpu0 2563470 73024 771178 11706192 4162 0 6297 0 0 0
cpu1 2520923 72652 770215 11711610 4177 0 6285 0 0 0
cpu2 2523933 72424 771628 11705234 4170 0 6314 0 0 0
cpu3 2523827 72596 771698 11705447 4174 0 6299 0 0 0
intr 620438388 38 0 0 0 0 0 0 0 1 0 0 0 156 0 0 0 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ctxt 1234567890
btime 1703462400
processes 123456
procs_running 3
procs_blocked 0
softirq 159613647 0 58361955 16888 39619257 14796 0 4275573 33379166 0 23926012
EOF

# =============================================================================
# /proc/loadavg - Load averages
# =============================================================================
cat > "$OUTDIR/proc/loadavg" << 'EOF'
1.52 1.23 0.98 3/892 12345
EOF

# =============================================================================
# /proc/meminfo - Memory statistics
# =============================================================================
cat > "$OUTDIR/proc/meminfo" << 'EOF'
MemTotal:       32768000 kB
MemFree:         4096000 kB
MemAvailable:   16384000 kB
Buffers:         1024000 kB
Cached:          8192000 kB
SwapCached:       512000 kB
Active:         12288000 kB
Inactive:        8192000 kB
Active(anon):    8192000 kB
Inactive(anon):  2048000 kB
Active(file):    4096000 kB
Inactive(file):  6144000 kB
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:       8388608 kB
SwapFree:        7340032 kB
Dirty:             12288 kB
Writeback:             0 kB
AnonPages:      10240000 kB
Mapped:          2048000 kB
Shmem:            512000 kB
KReclaimable:     768000 kB
Slab:            1024000 kB
SReclaimable:     768000 kB
SUnreclaim:       256000 kB
KernelStack:       16384 kB
PageTables:        65536 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    24576000 kB
Committed_AS:   20480000 kB
VmallocTotal:   34359738367 kB
VmallocUsed:       65536 kB
VmallocChunk:          0 kB
Percpu:            32768 kB
HardwareCorrupted:     0 kB
AnonHugePages:   2097152 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
DirectMap4k:      524288 kB
DirectMap2M:    16777216 kB
DirectMap1G:    16777216 kB
EOF

# =============================================================================
# /proc/vmstat - Virtual memory statistics
# =============================================================================
cat > "$OUTDIR/proc/vmstat" << 'EOF'
nr_free_pages 1024000
nr_zone_inactive_anon 512000
nr_zone_active_anon 2048000
nr_zone_inactive_file 1536000
nr_zone_active_file 1024000
nr_zone_unevictable 0
nr_zone_write_pending 3072
nr_mlock 0
nr_bounce 0
nr_zspages 0
nr_free_cma 0
numa_hit 123456789
numa_miss 0
numa_foreign 0
numa_interleave 12345
numa_local 123456789
numa_other 0
nr_inactive_anon 512000
nr_active_anon 2048000
nr_inactive_file 1536000
nr_active_file 1024000
nr_unevictable 0
nr_slab_reclaimable 192000
nr_slab_unreclaimable 64000
nr_isolated_anon 0
nr_isolated_file 0
workingset_nodes 12345
workingset_refault_anon 67890
workingset_refault_file 234567
workingset_activate_anon 12345
workingset_activate_file 67890
workingset_restore_anon 1234
workingset_restore_file 5678
workingset_nodereclaim 0
nr_anon_pages 2560000
nr_mapped 512000
nr_file_pages 2816000
nr_dirty 3072
nr_writeback 0
nr_writeback_temp 0
nr_shmem 128000
nr_shmem_hugepages 0
nr_shmem_pmdmapped 0
nr_file_hugepages 0
nr_file_pmdmapped 0
nr_anon_transparent_hugepages 512
nr_vmscan_write 12345
nr_vmscan_immediate_reclaim 0
nr_dirtied 98765432
nr_written 87654321
nr_kernel_misc_reclaimable 0
nr_foll_pin_acquired 0
nr_foll_pin_released 0
nr_kernel_stack 4096
pgpgin 123456789
pgpgout 234567890
pswpin 12345
pswpout 23456
pgalloc_dma 0
pgalloc_dma32 12345678
pgalloc_normal 987654321
pgalloc_movable 0
allocstall_dma 0
allocstall_dma32 0
allocstall_normal 123
allocstall_movable 0
pgskip_dma 0
pgskip_dma32 0
pgskip_normal 0
pgskip_movable 0
pgfree 1234567890
pgactivate 12345678
pgdeactivate 2345678
pglazyfree 123456
pgfault 987654321
pgmajfault 12345
pglazyfreed 98765
pgrefill 1234567
pgreuse 23456789
pgsteal_kswapd 12345678
pgsteal_direct 234567
pgdemote_kswapd 0
pgdemote_direct 0
pgscan_kswapd 23456789
pgscan_direct 345678
pgscan_direct_throttle 0
pgscan_anon 1234567
pgscan_file 22222222
pgsteal_anon 123456
pgsteal_file 12222222
zone_reclaim_failed 0
pginodesteal 12345
slabs_scanned 0
kswapd_inodesteal 234567
kswapd_low_wmark_hit_quickly 1234
kswapd_high_wmark_hit_quickly 567
pageoutrun 12345
pgrotated 2345
drop_pagecache 12
drop_slab 34
oom_kill 0
numa_pte_updates 0
numa_huge_pte_updates 0
numa_hint_faults 0
numa_hint_faults_local 0
numa_pages_migrated 0
pgmigrate_success 12345
pgmigrate_fail 123
thp_migration_success 12
thp_migration_fail 0
thp_migration_split 0
compact_migrate_scanned 1234567
compact_free_scanned 2345678
compact_isolated 123456
compact_stall 123
compact_fail 12
compact_success 111
compact_daemon_wake 234
compact_daemon_migrate_scanned 345678
compact_daemon_free_scanned 456789
htlb_buddy_alloc_success 0
htlb_buddy_alloc_fail 0
unevictable_pgs_culled 12345
unevictable_pgs_scanned 0
unevictable_pgs_rescued 1234
unevictable_pgs_mlocked 23456
unevictable_pgs_munlocked 23456
unevictable_pgs_cleared 0
unevictable_pgs_stranded 0
thp_fault_alloc 12345
thp_fault_fallback 1234
thp_fault_fallback_charge 0
thp_collapse_alloc 2345
thp_collapse_alloc_failed 123
thp_file_alloc 0
thp_file_fallback 0
thp_file_fallback_charge 0
thp_file_mapped 0
thp_split_page 234
thp_split_page_failed 12
thp_deferred_split_page 1234
thp_split_pmd 345
thp_split_pud 0
thp_zero_page_alloc 123
thp_zero_page_alloc_failed 0
thp_swpout 12
thp_swpout_fallback 34
balloon_inflate 0
balloon_deflate 0
balloon_migrate 0
swap_ra 12345
swap_ra_hit 11111
EOF

# =============================================================================
# /proc/diskstats - Disk I/O statistics
# =============================================================================
cat > "$OUTDIR/proc/diskstats" << 'EOF'
   8       0 sda 1234567 89012 345678901 234567 2345678 901234 567890123 345678 0 456789 580245 0 0 0 0 12345 67890
   8       1 sda1 123456 7890 12345678 23456 234567 89012 34567890 34567 0 45678 58024 0 0 0 0 1234 6789
   8       2 sda2 1111111 81122 333333223 211111 2111111 812222 533322233 311111 0 411111 522221 0 0 0 0 11111 61111
 259       0 nvme0n1 2345678 123456 789012345 345678 3456789 234567 890123456 456789 0 567890 802467 0 0 0 0 23456 78901
 259       1 nvme0n1p1 234567 12345 67890123 34567 345678 23456 78901234 45678 0 56789 80246 0 0 0 0 2345 7890
 259       2 nvme0n1p2 2111111 111111 721122222 311111 3111111 211111 811222222 411111 0 511101 722221 0 0 0 0 21111 71011
   7       0 loop0 123 0 1234 12 0 0 0 0 0 12 12 0 0 0 0 0 0
   7       1 loop1 456 0 4567 45 0 0 0 0 0 45 45 0 0 0 0 0 0
EOF

# =============================================================================
# /proc/net/dev - Network interface statistics
# =============================================================================
cat > "$OUTDIR/proc/net/dev" << 'EOF'
Inter-|   Receive                                                |  Transmit
 face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed
    lo: 12345678901  1234567    0    0    0     0          0         0 12345678901  1234567    0    0    0     0       0          0
  eth0: 98765432101 23456789   12   34    0     0          0      5678 87654321012 12345678   56   78    0     0       0          0
docker0: 1234567890  234567    0    0    0     0          0         0  2345678901  345678    0    0    0     0       0          0
veth1234: 123456789   12345    0    0    0     0          0         0   234567890   23456    0    0    0     0       0          0
EOF

# =============================================================================
# /proc/cpuinfo - CPU information
# =============================================================================
cat > "$OUTDIR/proc/cpuinfo" << 'EOF'
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 106
model name      : Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz
stepping        : 6
microcode       : 0xd0003a5
cpu MHz         : 2900.000
cache size      : 55296 KB
physical id     : 0
siblings        : 4
core id         : 0
cpu cores       : 4
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 27
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves wbnoinvd ida arat avx512vbmi pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilities
bugs            : spectre_v1 spectre_v2 spec_store_bypass swapgs
bogomips        : 5800.00
clflush size    : 64
cache_alignment : 64
address sizes   : 46 bits physical, 48 bits virtual
power management:

processor       : 1
vendor_id       : GenuineIntel
cpu family      : 6
model           : 106
model name      : Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz
stepping        : 6
microcode       : 0xd0003a5
cpu MHz         : 2900.000
cache size      : 55296 KB
physical id     : 0
siblings        : 4
core id         : 1
cpu cores       : 4
apicid          : 2
initial apicid  : 2
fpu             : yes
fpu_exception   : yes
cpuid level     : 27
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves wbnoinvd ida arat avx512vbmi pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilities
bugs            : spectre_v1 spectre_v2 spec_store_bypass swapgs
bogomips        : 5800.00
clflush size    : 64
cache_alignment : 64
address sizes   : 46 bits physical, 48 bits virtual
power management:

processor       : 2
vendor_id       : GenuineIntel
cpu family      : 6
model           : 106
model name      : Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz
stepping        : 6
microcode       : 0xd0003a5
cpu MHz         : 2900.000
cache size      : 55296 KB
physical id     : 0
siblings        : 4
core id         : 2
cpu cores       : 4
apicid          : 4
initial apicid  : 4
fpu             : yes
fpu_exception   : yes
cpuid level     : 27
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves wbnoinvd ida arat avx512vbmi pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilities
bugs            : spectre_v1 spectre_v2 spec_store_bypass swapgs
bogomips        : 5800.00
clflush size    : 64
cache_alignment : 64
address sizes   : 46 bits physical, 48 bits virtual
power management:

processor       : 3
vendor_id       : GenuineIntel
cpu family      : 6
model           : 106
model name      : Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz
stepping        : 6
microcode       : 0xd0003a5
cpu MHz         : 2900.000
cache size      : 55296 KB
physical id     : 0
siblings        : 4
core id         : 3
cpu cores       : 4
apicid          : 6
initial apicid  : 6
fpu             : yes
fpu_exception   : yes
cpuid level     : 27
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves wbnoinvd ida arat avx512vbmi pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg tme avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilities
bugs            : spectre_v1 spectre_v2 spec_store_bypass swapgs
bogomips        : 5800.00
clflush size    : 64
cache_alignment : 64
address sizes   : 46 bits physical, 48 bits virtual
power management:
EOF

# =============================================================================
# /proc/version - Kernel version
# =============================================================================
cat > "$OUTDIR/proc/version" << 'EOF'
Linux version 6.5.0-44-generic (buildd@lcy02-amd64-051) (x86_64-linux-gnu-gcc-12 (Ubuntu 12.3.0-1ubuntu1~23.04) 12.3.0, GNU ld (GNU Binutils for Ubuntu) 2.40) #44-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:10:09 UTC 2024
EOF

# =============================================================================
# /proc/self/cgroup - Container cgroup info (Docker example)
# =============================================================================
cat > "$OUTDIR/proc/self/cgroup" << 'EOF'
0::/docker/abc123def456789012345678901234567890123456789012345678901234
EOF

# =============================================================================
# Process 1 (init/systemd)
# =============================================================================
cat > "$OUTDIR/proc/1/stat" << 'EOF'
1 (systemd) S 0 1 1 0 -1 4194560 123456 78901234 123 456 7890 1234 56789 12345 20 0 1 0 12 234567890 12345 18446744073709551615 94123456789012 94123456901234 140123456789012 0 0 0 671173123 4096 1260 0 0 0 17 0 0 0 0 0 0 94123456912345 94123456923456 94123789012345 140123456789123 140123456789234 140123456789234 140123456789567 0
EOF

cat > "$OUTDIR/proc/1/status" << 'EOF'
Name:   systemd
Umask:  0000
State:  S (sleeping)
Tgid:   1
Ngid:   0
Pid:    1
PPid:   0
TracerPid:      0
Uid:    0       0       0       0
Gid:    0       0       0       0
FDSize: 256
Groups:
NStgid: 1
NSpid:  1
NSpgid: 1
NSsid:  1
VmPeak:   234568 kB
VmSize:   234568 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:     12345 kB
VmRSS:     12345 kB
RssAnon:            5678 kB
RssFile:            6667 kB
RssShmem:              0 kB
VmData:    18234 kB
VmStk:       132 kB
VmExe:      1416 kB
VmLib:      9876 kB
VmPTE:       128 kB
VmSwap:        0 kB
HugetlbPages:          0 kB
CoreDumping:    0
THP_enabled:    1
Threads:        1
SigQ:   0/123456
SigPnd: 0000000000000000
ShdPnd: 0000000000000000
SigBlk: 7be3c0fe28014a03
SigIgn: 0000000000001000
SigCgt: 00000001800004ec
CapInh: 0000000000000000
CapPrm: 000001ffffffffff
CapEff: 000001ffffffffff
CapBnd: 000001ffffffffff
CapAmb: 0000000000000000
NoNewPrivs:     0
Seccomp:        0
Seccomp_filters:        0
Speculation_Store_Bypass:       thread vulnerable
SpeculationIndirectBranch:      conditional enabled
Cpus_allowed:   f
Cpus_allowed_list:      0-3
Mems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001
Mems_allowed_list:      0
voluntary_ctxt_switches:        123456
nonvoluntary_ctxt_switches:     7890
EOF

cat > "$OUTDIR/proc/1/statm" << 'EOF'
58642 3086 1666 354 0 4558 0
EOF

printf 'systemd\x00--switched-root\x00--system\x00--deserialize\x0028\x00' > "$OUTDIR/proc/1/cmdline"

# =============================================================================
# Process 42 (example user process)
# =============================================================================
cat > "$OUTDIR/proc/42/stat" << 'EOF'
42 (python3) S 1 42 42 0 -1 4194304 567890 0 123 0 45678 12345 0 0 20 0 4 0 1234 1234567890 234567 18446744073709551615 94234567890123 94234567901234 140234567890123 0 0 0 0 0 65536 1 0 0 17 2 0 0 0 0 0 94234567912345 94234567923456 94234789012345 140234567890234 140234567890345 140234567890345 140234567890678 0
EOF

cat > "$OUTDIR/proc/42/status" << 'EOF'
Name:   python3
Umask:  0022
State:  S (sleeping)
Tgid:   42
Ngid:   0
Pid:    42
PPid:   1
TracerPid:      0
Uid:    1000    1000    1000    1000
Gid:    1000    1000    1000    1000
FDSize: 64
Groups: 4 24 27 30 46 100 118 1000
NStgid: 42
NSpid:  42
NSpgid: 42
NSsid:  42
VmPeak:  1234568 kB
VmSize:  1234568 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:    234567 kB
VmRSS:    234567 kB
RssAnon:          200000 kB
RssFile:           34567 kB
RssShmem:              0 kB
VmData:   456789 kB
VmStk:       136 kB
VmExe:      2828 kB
VmLib:     45678 kB
VmPTE:      1024 kB
VmSwap:        0 kB
HugetlbPages:          0 kB
CoreDumping:    0
THP_enabled:    1
Threads:        4
SigQ:   1/123456
SigPnd: 0000000000000000
ShdPnd: 0000000000000000
SigBlk: 0000000000000000
SigIgn: 0000000001001000
SigCgt: 0000000180014a07
CapInh: 0000000000000000
CapPrm: 0000000000000000
CapEff: 0000000000000000
CapBnd: 000001ffffffffff
CapAmb: 0000000000000000
NoNewPrivs:     0
Seccomp:        0
Seccomp_filters:        0
Speculation_Store_Bypass:       thread vulnerable
SpeculationIndirectBranch:      conditional enabled
Cpus_allowed:   f
Cpus_allowed_list:      0-3
Mems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001
Mems_allowed_list:      0
voluntary_ctxt_switches:        98765
nonvoluntary_ctxt_switches:     4321
EOF

cat > "$OUTDIR/proc/42/statm" << 'EOF'
308642 58641 8641 707 0 114197 0
EOF

printf '/usr/bin/python3\x00-m\x00vllm.entrypoints.openai.api_server\x00--model\x00/app/model/\x00' > "$OUTDIR/proc/42/cmdline"

# =============================================================================
# Process 1337 (example GPU process)
# =============================================================================
cat > "$OUTDIR/proc/1337/stat" << 'EOF'
1337 (cuda_worker) R 42 42 42 0 -1 4194304 890123 0 456 0 78901 23456 0 0 20 0 1 0 5678 2345678901 345678 18446744073709551615 94345678901234 94345678912345 140345678901234 0 0 0 0 0 65536 1 0 0 17 1 0 0 0 0 0 94345678923456 94345678934567 94345890123456 140345678901345 140345678901456 140345678901456 140345678901789 0
EOF

cat > "$OUTDIR/proc/1337/status" << 'EOF'
Name:   cuda_worker
Umask:  0022
State:  R (running)
Tgid:   1337
Ngid:   0
Pid:    1337
PPid:   42
TracerPid:      0
Uid:    1000    1000    1000    1000
Gid:    1000    1000    1000    1000
FDSize: 128
Groups: 4 24 27 30 46 100 118 1000
NStgid: 1337
NSpid:  1337
NSpgid: 42
NSsid:  42
VmPeak:  8765432 kB
VmSize:  8765432 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:   4567890 kB
VmRSS:   4567890 kB
RssAnon:         4000000 kB
RssFile:          567890 kB
RssShmem:              0 kB
VmData:  6789012 kB
VmStk:       136 kB
VmExe:      2828 kB
VmLib:    123456 kB
VmPTE:      8192 kB
VmSwap:        0 kB
HugetlbPages:          0 kB
CoreDumping:    0
THP_enabled:    1
Threads:        1
SigQ:   2/123456
SigPnd: 0000000000000000
ShdPnd: 0000000000000000
SigBlk: 0000000000000000
SigIgn: 0000000001001000
SigCgt: 0000000180014a07
CapInh: 0000000000000000
CapPrm: 0000000000000000
CapEff: 0000000000000000
CapBnd: 000001ffffffffff
CapAmb: 0000000000000000
NoNewPrivs:     0
Seccomp:        0
Seccomp_filters:        0
Speculation_Store_Bypass:       thread vulnerable
SpeculationIndirectBranch:      conditional enabled
Cpus_allowed:   f
Cpus_allowed_list:      0-3
Mems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001
Mems_allowed_list:      0
voluntary_ctxt_switches:        543210
nonvoluntary_ctxt_switches:     12345
EOF

cat > "$OUTDIR/proc/1337/statm" << 'EOF'
2191358 1141972 141972 707 0 1697253 0
EOF

printf 'cuda_worker\x00--batch-size\x0032\x00' > "$OUTDIR/proc/1337/cmdline"

# =============================================================================
# CPU sysfs - frequency and cache info
# =============================================================================
for cpu in 0 1 2 3; do
    echo "2900000" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cpufreq/scaling_cur_freq"

    # L1 data cache
    mkdir -p "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index0"
    echo "1" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index0/level"
    echo "Data" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index0/type"
    echo "48K" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index0/size"
    printf '%02x' "$cpu" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index0/shared_cpu_map"

    # L1 instruction cache
    mkdir -p "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index1"
    echo "1" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index1/level"
    echo "Instruction" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index1/type"
    echo "32K" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index1/size"
    printf '%02x' "$cpu" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index1/shared_cpu_map"

    # L2 cache (per-core)
    mkdir -p "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index2"
    echo "2" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index2/level"
    echo "Unified" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index2/type"
    echo "1280K" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index2/size"
    printf '%02x' "$cpu" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index2/shared_cpu_map"

    # L3 cache (shared across all cores)
    mkdir -p "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index3"
    echo "3" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index3/level"
    echo "Unified" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index3/type"
    echo "55296K" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index3/size"
    echo "0f" > "$OUTDIR/sys/devices/system/cpu/cpu$cpu/cache/index3/shared_cpu_map"
done

# =============================================================================
# DMI info
# =============================================================================
echo "EC2ABCD1-2345-6789-ABCD-EF0123456789" > "$OUTDIR/sys/class/dmi/id/product_uuid"

# =============================================================================
# Machine ID fallback
# =============================================================================
mkdir -p "$OUTDIR/etc"
echo "abc123def456789012345678901234ab" > "$OUTDIR/etc/machine-id"

# =============================================================================
# Cgroup v2 files
# =============================================================================
mkdir -p "$OUTDIR/sys/fs/cgroup"
echo "cpuset cpu io memory hugetlb pids rdma misc" > "$OUTDIR/sys/fs/cgroup/cgroup.controllers"

cat > "$OUTDIR/sys/fs/cgroup/cpu.stat" << 'EOF'
usage_usec 123456789012
user_usec 98765432109
system_usec 24691356903
nr_periods 0
nr_throttled 0
throttled_usec 0
nr_bursts 0
burst_usec 0
EOF

echo "8589934592" > "$OUTDIR/sys/fs/cgroup/memory.current"
echo "12884901888" > "$OUTDIR/sys/fs/cgroup/memory.peak"

cat > "$OUTDIR/sys/fs/cgroup/io.stat" << 'EOF'
8:0 rbytes=12345678901 wbytes=9876543210 rios=123456 wios=98765 dbytes=0 dios=0
259:0 rbytes=23456789012 wbytes=8765432109 rios=234567 wios=87654 dbytes=0 dios=0
EOF

# =============================================================================
# Cgroup v1 files (alternative)
# =============================================================================
mkdir -p "$OUTDIR/sys/fs/cgroup_v1"/{cpuacct,memory,blkio}

echo "1234567890123456789" > "$OUTDIR/sys/fs/cgroup_v1/cpuacct/cpuacct.usage"

cat > "$OUTDIR/sys/fs/cgroup_v1/cpuacct/cpuacct.stat" << 'EOF'
user 987654321
system 246913569
EOF

echo "308642000000 308641000000 308640000000 308639000000" > "$OUTDIR/sys/fs/cgroup_v1/cpuacct/cpuacct.usage_percpu"

echo "8589934592" > "$OUTDIR/sys/fs/cgroup_v1/memory/memory.usage_in_bytes"
echo "12884901888" > "$OUTDIR/sys/fs/cgroup_v1/memory/memory.max_usage_in_bytes"

cat > "$OUTDIR/sys/fs/cgroup_v1/blkio/blkio.throttle.io_service_bytes" << 'EOF'
8:0 Read 12345678901
8:0 Write 9876543210
8:0 Sync 11111111111
8:0 Async 11111111000
8:0 Discard 0
8:0 Total 22222222111
259:0 Read 23456789012
259:0 Write 8765432109
259:0 Sync 16111111061
259:0 Async 16111110060
259:0 Discard 0
259:0 Total 32222221121
Total 54444443232
EOF

# =============================================================================
# vLLM Prometheus metrics sample
# =============================================================================
cat > "$OUTDIR/vllm_metrics.txt" << 'EOF'
# HELP vllm:num_requests_running Number of requests currently running on GPU.
# TYPE vllm:num_requests_running gauge
vllm:num_requests_running{model_name="llama-3.2-1b"} 3
# HELP vllm:num_requests_waiting Number of requests waiting to be processed.
# TYPE vllm:num_requests_waiting gauge
vllm:num_requests_waiting{model_name="llama-3.2-1b"} 12
# HELP vllm:engine_sleep_state Sleep state of the engine.
# TYPE vllm:engine_sleep_state gauge
vllm:engine_sleep_state{model_name="llama-3.2-1b"} 1
# HELP vllm:kv_cache_usage_perc GPU KV-cache usage. 1 means 100 percent usage.
# TYPE vllm:kv_cache_usage_perc gauge
vllm:kv_cache_usage_perc{model_name="llama-3.2-1b"} 0.42
# HELP vllm:num_preemptions Total preemptions.
# TYPE vllm:num_preemptions counter
vllm:num_preemptions{model_name="llama-3.2-1b"} 5
# HELP vllm:prefix_cache_hits Prefix cache hits.
# TYPE vllm:prefix_cache_hits counter
vllm:prefix_cache_hits{model_name="llama-3.2-1b"} 1234
# HELP vllm:prefix_cache_queries Prefix cache queries.
# TYPE vllm:prefix_cache_queries counter
vllm:prefix_cache_queries{model_name="llama-3.2-1b"} 5678
# HELP vllm:request_success Successful requests.
# TYPE vllm:request_success counter
vllm:request_success{model_name="llama-3.2-1b"} 9876
# HELP vllm:prompt_tokens Total prompt tokens processed.
# TYPE vllm:prompt_tokens counter
vllm:prompt_tokens{model_name="llama-3.2-1b"} 1234567
# HELP vllm:generation_tokens Total generation tokens produced.
# TYPE vllm:generation_tokens counter
vllm:generation_tokens{model_name="llama-3.2-1b"} 2345678
# HELP vllm:time_to_first_token_seconds Histogram of time to first token in seconds.
# TYPE vllm:time_to_first_token_seconds histogram
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.001"} 0
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.005"} 12
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.01"} 45
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.025"} 234
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.05"} 567
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.075"} 789
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.1"} 890
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.15"} 901
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.2"} 912
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.3"} 923
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.4"} 934
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.5"} 945
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="0.75"} 956
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="1.0"} 967
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="2.5"} 978
vllm:time_to_first_token_seconds_bucket{model_name="llama-3.2-1b",le="+Inf"} 987
vllm:time_to_first_token_seconds_count{model_name="llama-3.2-1b"} 987
vllm:time_to_first_token_seconds_sum{model_name="llama-3.2-1b"} 123.456
# HELP vllm:e2e_request_latency_seconds Histogram of end-to-end request latency in seconds.
# TYPE vllm:e2e_request_latency_seconds histogram
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="0.1"} 100
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="0.5"} 500
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="1.0"} 800
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="2.5"} 950
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="5.0"} 980
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="10.0"} 990
vllm:e2e_request_latency_seconds_bucket{model_name="llama-3.2-1b",le="+Inf"} 1000
vllm:e2e_request_latency_seconds_count{model_name="llama-3.2-1b"} 1000
vllm:e2e_request_latency_seconds_sum{model_name="llama-3.2-1b"} 987.654
# HELP vllm:cache_config_info Cache configuration info
# TYPE vllm:cache_config_info gauge
vllm:cache_config_info{block_size="16",cache_dtype="auto",num_gpu_blocks="2048",num_cpu_blocks="512"} 1
EOF

echo ""
echo "Test data generated in $OUTDIR/"
echo ""
echo "Directory structure:"
find "$OUTDIR" -type f | head -40
echo "..."
echo ""
echo "To use in tests, set environment variables or mock file paths to point to $OUTDIR"
module github.com/inference-profiler

go 1.22
# Inference Profiler

System resource profiler for monitoring VM, container, process, and GPU metrics during ML inference workloads. Exports to JSON, CSV, or Parquet.

## Quick Start

```bash
# Build
go build -o profiler ./cmd/profiler

# Run standalone (Ctrl+C to stop)
./profiler -o ./output -t 1000

# Profile a command
./profiler -o ./output -- python serve.py
```

## Features

- **VM Metrics**: CPU, memory, disk I/O, network
- **Container Metrics**: cgroup v1/v2, per-container resource usage
- **Process Metrics**: Per-process CPU, memory, threads, context switches
- **GPU Metrics**: NVIDIA GPU utilization, memory, power, temperature
- **vLLM Metrics**: Inference engine statistics from Prometheus endpoint

## Flags

| Flag | Default | Description |
|------|---------|-------------|
| `-o, --output` | `./profiler-output` | Output directory |
| `-t, --interval` | `1000` | Sampling interval (ms) |
| `-f, --format` | `parquet` | Export format: csv, tsv, parquet |
| `-p, --processes` | `false` | Enable per-process metrics |

## Output Structure

```
output/
├── static_<uuid>.json      # Hardware info (once at start)
├── <uuid>-<timestamp>.json # Per-sample snapshots
└── <uuid>.csv              # Aggregated time series
```

## Metrics Reference

### CPU (`cpu`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `vCpuTime` | Timed[int64] | cs | Total CPU time (user + kernel) |
| `vCpuTimeUserMode` | Timed[int64] | cs | User space execution time |
| `vCpuTimeKernelMode` | Timed[int64] | cs | Kernel execution time |
| `vCpuIdleTime` | Timed[int64] | cs | Idle time |
| `vCpuTimeIOWait` | Timed[int64] | cs | I/O wait time |
| `vCpuTimeIntSrvc` | Timed[int64] | cs | Hardware interrupt time |
| `vCpuTimeSoftIntSrvc` | Timed[int64] | cs | Software interrupt time |
| `vCpuNice` | Timed[int64] | cs | Nice process time |
| `vCpuSteal` | Timed[int64] | cs | Hypervisor stolen time |
| `vCpuContextSwitches` | Timed[int64] | count | Context switches |
| `vLoadAvg` | Timed[float64] | ratio | 1-min load average |
| `vCpuMhz` | Timed[float64] | MHz | Current CPU frequency |

### Memory (`mem`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `vMemoryTotal` | Timed[int64] | bytes | Total RAM |
| `vMemoryFree` | Timed[int64] | bytes | Available memory |
| `vMemoryUsed` | Timed[int64] | bytes | Used memory |
| `vMemoryBuffers` | Timed[int64] | bytes | Kernel buffers |
| `vMemoryCached` | Timed[int64] | bytes | Page cache |
| `vMemoryPercent` | Timed[float64] | % | Usage percentage |
| `vSwapTotal` | Timed[int64] | bytes | Total swap |
| `vSwapFree` | Timed[int64] | bytes | Free swap |
| `vSwapUsed` | Timed[int64] | bytes | Used swap |
| `vPgFault` | Timed[int64] | count | Minor page faults |
| `vMajorPageFault` | Timed[int64] | count | Major page faults |

### Disk (`disk`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `vDiskReadBytes` | Timed[int64] | bytes | Bytes read |
| `vDiskWriteBytes` | Timed[int64] | bytes | Bytes written |
| `vDiskSuccessfulReads` | Timed[int64] | count | Read operations |
| `vDiskSuccessfulWrites` | Timed[int64] | count | Write operations |
| `vDiskReadTime` | Timed[int64] | ms | Time reading |
| `vDiskWriteTime` | Timed[int64] | ms | Time writing |
| `vDiskIOTime` | Timed[int64] | ms | Total I/O time |
| `vDiskIOInProgress` | Timed[int64] | count | In-flight I/O |

### Network (`net`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `vNetworkBytesRecvd` | Timed[int64] | bytes | Bytes received |
| `vNetworkBytesSent` | Timed[int64] | bytes | Bytes sent |
| `vNetworkPacketsRecvd` | Timed[int64] | count | Packets received |
| `vNetworkPacketsSent` | Timed[int64] | count | Packets sent |
| `vNetworkErrorsRecvd` | Timed[int64] | count | Receive errors |
| `vNetworkErrorsSent` | Timed[int64] | count | Send errors |
| `vNetworkDropsRecvd` | Timed[int64] | count | Receive drops |
| `vNetworkDropsSent` | Timed[int64] | count | Send drops |

### Container (`containers`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `cId` | string | - | Container ID |
| `cCgroupVersion` | int | - | Cgroup version (1 or 2) |
| `cCpuTime` | Timed[int64] | ns | Total CPU time |
| `cCpuTimeUserMode` | Timed[int64] | cs | User mode time |
| `cCpuTimeKernelMode` | Timed[int64] | cs | Kernel mode time |
| `cMemoryUsed` | Timed[int64] | bytes | Current memory |
| `cMemoryMaxUsed` | Timed[int64] | bytes | Peak memory |
| `cDiskReadBytes` | Timed[int64] | bytes | Bytes read |
| `cDiskWriteBytes` | Timed[int64] | bytes | Bytes written |
| `cNetworkBytesRecvd` | Timed[int64] | bytes | Network received |
| `cNetworkBytesSent` | Timed[int64] | bytes | Network sent |

### GPU (`nvidia[]`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `gGpuIndex` | int | - | GPU index |
| `gUtilizationGpu` | Timed[int] | % | GPU utilization |
| `gUtilizationMem` | Timed[int] | % | Memory utilization |
| `gMemoryUsedMb` | Timed[int64] | MB | Used VRAM |
| `gMemoryFreeMb` | Timed[int64] | MB | Free VRAM |
| `gTemperatureC` | Timed[int] | °C | Temperature |
| `gPowerDrawW` | Timed[float64] | W | Power draw |
| `gClockGraphicsMhz` | Timed[int] | MHz | Graphics clock |
| `gPerfState` | Timed[string] | - | Performance state |

### vLLM (`vllm`)

| Field | Type | Unit | Description |
|-------|------|------|-------------|
| `system_requests_running` | float64 | count | Active requests |
| `system_requests_waiting` | float64 | count | Queued requests |
| `cache_kv_usage_percent` | float64 | ratio | KV cache usage |
| `requests_finished_total` | float64 | count | Completed requests |
| `tokens_prompt_total` | float64 | count | Prompt tokens |
| `tokens_generation_total` | float64 | count | Generated tokens |
| `latency_ttft_s_sum` | float64 | s | Time to first token (sum) |
| `latency_e2e_s_sum` | float64 | s | End-to-end latency (sum) |

## Timed Values

All metrics that change over time include timestamps for accurate rate calculations:

```json
{
  "vCpuTime": {
    "value": 12345678,
    "time": 1703462400000
  }
}
```

The `time` field is Unix milliseconds.

## Testing

Generate mock procfs/sysfs data:

```bash
./scripts/generate_testdata.sh testdata
```

Run tests:

```bash
go test -v ./...
```

## Data Sources

| Metric Type | Source |
|-------------|--------|
| CPU | `/proc/stat`, `/proc/loadavg`, sysfs cpufreq |
| Memory | `/proc/meminfo`, `/proc/vmstat` |
| Disk | `/proc/diskstats` |
| Network | `/proc/net/dev` |
| Container | `/sys/fs/cgroup` (v1 and v2) |
| GPU | NVML (via go-nvml) |
| vLLM | HTTP `/metrics` (Prometheus format) |

## License

MIT
# Makefile for inference-profiler (Go)

PROJECT_NAME := inference-profiler
BINARY       := profiler
OUTPUT_DIR   := ./output
TESTDATA_DIR := ./testdata

.PHONY: all build test clean run testdata help

all: build

help: ## Show this help
        @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-15s\033[0m %s\n", $$1, $$2}'

build: ## Build the profiler binary
        @echo "Building $(BINARY)..."
        go build -o $(BINARY) .

test: testdata ## Run tests
        go test -v ./...

testdata: ## Generate test data files
        @./scripts/generate_testdata.sh $(TESTDATA_DIR)

run: build ## Run profiler locally
        @mkdir -p $(OUTPUT_DIR)
        ./$(BINARY) -o $(OUTPUT_DIR) -t 1000

clean: ## Remove build artifacts
        rm -rf $(BINARY) $(OUTPUT_DIR) $(TESTDATA_DIR)
        go clean

fmt: ## Format code
        go fmt ./...

lint: ## Run linter
        @command -v golangci-lint >/dev/null 2>&1 || { echo "golangci-lint not installed"; exit 1; }
        golangci-lint run

deps: ## Download dependencies
        go mod download
        go mod tidy
package collectors

import (
        "os"
        "path/filepath"
        "strconv"
        "strings"

        "github.com/inference-profiler"
)

// ContainerMetrics contains container-level measurements from cgroups.
type ContainerMetrics struct {
        // Identification
        ID            string `json:"cId"`            // Container ID (Docker/K8s short ID)
        CgroupVersion int    `json:"cCgroupVersion"` // 1 or 2

        // CPU (time in nanoseconds for total, centiseconds for user/kernel)
        CPUTime       exporter.Timed[int64] `json:"cCpuTime"`           // Total CPU nanoseconds
        CPUUserMode   exporter.Timed[int64] `json:"cCpuTimeUserMode"`   // User mode centiseconds
        CPUKernelMode exporter.Timed[int64] `json:"cCpuTimeKernelMode"` // Kernel mode centiseconds
        NumProcessors int                   `json:"cNumProcessors"`     // Available CPUs

        // Per-CPU times (cgroup v1 only)
        PerCPU map[string]exporter.Timed[int64] `json:"perCpu,omitempty"` // cCpu{i}Time in nanoseconds

        // Memory (bytes)
        MemoryUsed    exporter.Timed[int64] `json:"cMemoryUsed"`    // Current usage
        MemoryMaxUsed exporter.Timed[int64] `json:"cMemoryMaxUsed"` // Peak usage

        // Disk I/O (bytes)
        DiskReadBytes  exporter.Timed[int64] `json:"cDiskReadBytes"`
        DiskWriteBytes exporter.Timed[int64] `json:"cDiskWriteBytes"`

        // Network (bytes, from container namespace)
        NetBytesRecvd exporter.Timed[int64] `json:"cNetworkBytesRecvd"`
        NetBytesSent  exporter.Timed[int64] `json:"cNetworkBytesSent"`
}

const cgroupDir = "/sys/fs/cgroup"

// CollectContainer gathers container metrics from cgroups.
// Auto-detects cgroup v1 vs v2.
func CollectContainer() ContainerMetrics {
        if _, err := os.Stat(cgroupDir); err != nil {
                return ContainerMetrics{}
        }

        if isCgroupV2() {
                return collectCgroupV2()
        }
        return collectCgroupV1()
}

// isCgroupV2 checks for cgroup v2 unified hierarchy.
func isCgroupV2() bool {
        _, err := os.Stat(filepath.Join(cgroupDir, "cgroup.controllers"))
        return err == nil
}

// getContainerID attempts to detect container ID from /proc/self/cgroup or hostname.
func getContainerID() string {
        lines, _ := exporter.readLines("/proc/self/cgroup")
        for _, line := range lines {
                parts := strings.SplitN(line, ":", 3)
                if len(parts) < 3 {
                        continue
                }
                path := parts[2]

                // Docker format: /docker/<container_id>
                if idx := strings.Index(path, "/docker/"); idx >= 0 {
                        id := path[idx+8:]
                        if len(id) > 12 {
                                id = id[:12]
                        }
                        return id
                }

                // Kubernetes format: /kubepods/.../<container_id>
                if strings.Contains(path, "/kubepods/") {
                        segments := strings.Split(path, "/")
                        if len(segments) > 0 {
                                id := segments[len(segments)-1]
                                if len(id) > 12 {
                                        id = id[:12]
                                }
                                return id
                        }
                }
        }

        // Fallback: hostname (often set to container ID)
        hostname, _ := os.Hostname()
        if len(hostname) == 12 && isHex(hostname) {
                return hostname
        }

        return "unavailable"
}

func isHex(s string) bool {
        for _, c := range strings.ToLower(s) {
                if !((c >= '0' && c <= '9') || (c >= 'a' && c <= 'f')) {
                        return false
                }
        }
        return true
}

// collectCgroupV1 gathers metrics from cgroup v1 hierarchy.
func collectCgroupV1() ContainerMetrics {
        cpuUsage, cpuTS := exporter.readInt(filepath.Join(cgroupDir, "cpuacct", "cpuacct.usage"))

        cpuStat, cpuStatTS := exporter.parseKV(filepath.Join(cgroupDir, "cpuacct", "cpuacct.stat"), ' ')
        userJiffies, _ := strconv.ParseInt(cpuStat["user"], 10, 64)
        systemJiffies, _ := strconv.ParseInt(cpuStat["system"], 10, 64)

        memUsage, memTS := exporter.readInt(filepath.Join(cgroupDir, "memory", "memory.usage_in_bytes"))
        memMax, memMaxTS := exporter.readInt(filepath.Join(cgroupDir, "memory", "memory.max_usage_in_bytes"))

        diskRead, diskWrite, blkioTS := parseBlkioV1(filepath.Join(cgroupDir, "blkio", "blkio.throttle.io_service_bytes"))

        netRecv, netSent, netTS := getContainerNetStats()

        perCPU := getPerCPUV1()

        return ContainerMetrics{
                ID:             getContainerID(),
                CgroupVersion:  1,
                CPUTime:        exporter.TimedAt(cpuUsage, cpuTS),
                CPUUserMode:    exporter.TimedAt(userJiffies*jiffiesPerSec, cpuStatTS),
                CPUKernelMode:  exporter.TimedAt(systemJiffies*jiffiesPerSec, cpuStatTS),
                NumProcessors:  getNumCPU(),
                PerCPU:         perCPU,
                MemoryUsed:     exporter.TimedAt(memUsage, memTS),
                MemoryMaxUsed:  exporter.TimedAt(memMax, memMaxTS),
                DiskReadBytes:  exporter.TimedAt(diskRead, blkioTS),
                DiskWriteBytes: exporter.TimedAt(diskWrite, blkioTS),
                NetBytesRecvd:  exporter.TimedAt(netRecv, netTS),
                NetBytesSent:   exporter.TimedAt(netSent, netTS),
        }
}

// collectCgroupV2 gathers metrics from cgroup v2 unified hierarchy.
func collectCgroupV2() ContainerMetrics {
        cpuStat, cpuTS := exporter.parseKV(filepath.Join(cgroupDir, "cpu.stat"), ' ')
        usageUsec, _ := strconv.ParseInt(cpuStat["usage_usec"], 10, 64)
        userUsec, _ := strconv.ParseInt(cpuStat["user_usec"], 10, 64)
        systemUsec, _ := strconv.ParseInt(cpuStat["system_usec"], 10, 64)

        memUsage, memTS := exporter.readInt(filepath.Join(cgroupDir, "memory.current"))
        memPeak, memPeakTS := exporter.readInt(filepath.Join(cgroupDir, "memory.peak"))

        diskRead, diskWrite, ioTS := parseIOStatV2(filepath.Join(cgroupDir, "io.stat"))

        netRecv, netSent, netTS := getContainerNetStats()

        return ContainerMetrics{
                ID:             getContainerID(),
                CgroupVersion:  2,
                CPUTime:        exporter.TimedAt(usageUsec*1000, cpuTS), // usec -> ns
                CPUUserMode:    exporter.TimedAt(userUsec/10000, cpuTS), // usec -> cs
                CPUKernelMode:  exporter.TimedAt(systemUsec/10000, cpuTS),
                NumProcessors:  getNumCPU(),
                MemoryUsed:     exporter.TimedAt(memUsage, memTS),
                MemoryMaxUsed:  exporter.TimedAt(memPeak, memPeakTS),
                DiskReadBytes:  exporter.TimedAt(diskRead, ioTS),
                DiskWriteBytes: exporter.TimedAt(diskWrite, ioTS),
                NetBytesRecvd:  exporter.TimedAt(netRecv, netTS),
                NetBytesSent:   exporter.TimedAt(netSent, netTS),
        }
}

// getPerCPUV1 reads per-CPU usage from cgroup v1.
func getPerCPUV1() map[string]exporter.Timed[int64] {
        result := make(map[string]exporter.Timed[int64])
        content, ts := exporter.readFile(filepath.Join(cgroupDir, "cpuacct", "cpuacct.usage_percpu"))
        if content == "" {
                return result
        }

        fields := strings.Fields(content)
        for i, val := range fields {
                v, err := strconv.ParseInt(val, 10, 64)
                if err != nil {
                        continue
                }
                key := "cCpu" + strconv.Itoa(i) + "Time"
                result[key] = exporter.TimedAt(v, ts)
        }
        return result
}

// parseBlkioV1 parses blkio.throttle.io_service_bytes for v1.
func parseBlkioV1(path string) (read, write, ts int64) {
        lines, ts := exporter.readLines(path)
        for _, line := range lines {
                fields := strings.Fields(line)
                if len(fields) < 3 {
                        continue
                }
                op := strings.ToLower(fields[1])
                val, _ := strconv.ParseInt(fields[2], 10, 64)
                switch op {
                case "read":
                        read += val
                case "write":
                        write += val
                }
        }
        return read, write, ts
}

// parseIOStatV2 parses io.stat for cgroup v2.
func parseIOStatV2(path string) (read, write, ts int64) {
        lines, ts := exporter.readLines(path)
        for _, line := range lines {
                // Format: "major:minor rbytes=X wbytes=Y rios=Z wios=W ..."
                fields := strings.Fields(line)
                for _, f := range fields {
                        if strings.HasPrefix(f, "rbytes=") {
                                val, _ := strconv.ParseInt(f[7:], 10, 64)
                                read += val
                        } else if strings.HasPrefix(f, "wbytes=") {
                                val, _ := strconv.ParseInt(f[7:], 10, 64)
                                write += val
                        }
                }
        }
        return read, write, ts
}

// getContainerNetStats reads /proc/net/dev from container's namespace.
func getContainerNetStats() (recv, sent, ts int64) {
        lines, ts := exporter.readLines("/proc/net/dev")

        // Skip headers
        for i := 2; i < len(lines); i++ {
                line := lines[i]
                colonIdx := strings.Index(line, ":")
                if colonIdx < 0 {
                        continue
                }

                iface := strings.TrimSpace(line[:colonIdx])
                if iface == "lo" {
                        continue
                }

                fields := strings.Fields(line[colonIdx+1:])
                if len(fields) < 9 {
                        continue
                }

                r, _ := strconv.ParseInt(fields[0], 10, 64)
                s, _ := strconv.ParseInt(fields[8], 10, 64)
                recv += r
                sent += s
        }
        return recv, sent, ts
}
package collectors

import (
        "path/filepath"
        "strconv"
        "strings"
        "time"

        "github.com/inference-profiler"
)

// CPUMetrics contains VM-level CPU measurements.
// All time values are in centiseconds (1 cs = 10ms).
type CPUMetrics struct {
        // Aggregate CPU time
        Time       exporter.Timed[int64] `json:"vCpuTime"`            // User + Kernel time
        UserMode   exporter.Timed[int64] `json:"vCpuTimeUserMode"`    // User space execution
        KernelMode exporter.Timed[int64] `json:"vCpuTimeKernelMode"`  // Kernel execution
        Idle       exporter.Timed[int64] `json:"vCpuIdleTime"`        // Idle state
        IOWait     exporter.Timed[int64] `json:"vCpuTimeIOWait"`      // Waiting for I/O
        IRQ        exporter.Timed[int64] `json:"vCpuTimeIntSrvc"`     // Hardware interrupts
        SoftIRQ    exporter.Timed[int64] `json:"vCpuTimeSoftIntSrvc"` // Software interrupts
        Nice       exporter.Timed[int64] `json:"vCpuNice"`            // Low priority user procs
        Steal      exporter.Timed[int64] `json:"vCpuSteal"`           // Stolen by hypervisor

        // Performance counters
        ContextSwitches exporter.Timed[int64]   `json:"vCpuContextSwitches"` // Total context switches
        LoadAvg         exporter.Timed[float64] `json:"vLoadAvg"`            // 1-min load average
        FreqMHz         exporter.Timed[float64] `json:"vCpuMhz"`             // Current avg frequency
}

// CPUStatic contains static CPU information.
type CPUStatic struct {
        NumProcessors int              `json:"vNumProcessors"` // Logical CPU count
        Model         string           `json:"vCpuType"`       // Processor model
        Cache         map[string]int64 `json:"vCpuCache"`      // Cache sizes (L1d, L1i, L2, L3)
        KernelInfo    string           `json:"vKernelInfo"`    // Kernel version
}

const jiffiesPerSec = 100 // Standard Linux jiffy rate

// CollectCPU gathers CPU metrics from /proc/stat, /proc/loadavg, and sysfs.
func CollectCPU() CPUMetrics {
        stat, ts := parseProcStat()
        load, loadTS := parseLoadAvg()
        freq, freqTS := getCPUFreq()

        user := stat["user"]
        system := stat["system"]

        return CPUMetrics{
                Time:            exporter.TimedAt((user+system)*jiffiesPerSec, ts),
                UserMode:        exporter.TimedAt(user*jiffiesPerSec, ts),
                KernelMode:      exporter.TimedAt(system*jiffiesPerSec, ts),
                Idle:            exporter.TimedAt(stat["idle"]*jiffiesPerSec, ts),
                IOWait:          exporter.TimedAt(stat["iowait"]*jiffiesPerSec, ts),
                IRQ:             exporter.TimedAt(stat["irq"]*jiffiesPerSec, ts),
                SoftIRQ:         exporter.TimedAt(stat["softirq"]*jiffiesPerSec, ts),
                Nice:            exporter.TimedAt(stat["nice"]*jiffiesPerSec, ts),
                Steal:           exporter.TimedAt(stat["steal"]*jiffiesPerSec, ts),
                ContextSwitches: exporter.TimedAt(stat["ctxt"], ts),
                LoadAvg:         exporter.TimedAt(load, loadTS),
                FreqMHz:         exporter.TimedAt(freq, freqTS),
        }
}

// CollectCPUStatic gathers static CPU info.
func CollectCPUStatic() CPUStatic {
        return CPUStatic{
                NumProcessors: getNumCPU(),
                Model:         getCPUModel(),
                Cache:         getCPUCache(),
                KernelInfo:    getKernelInfo(),
        }
}

// parseProcStat parses /proc/stat for CPU and context switch counters.
func parseProcStat() (map[string]int64, int64) {
        lines, ts := exporter.readLines("/proc/stat")
        m := map[string]int64{
                "user": 0, "nice": 0, "system": 0, "idle": 0,
                "iowait": 0, "irq": 0, "softirq": 0, "steal": 0, "ctxt": 0,
        }

        for _, line := range lines {
                fields := strings.Fields(line)
                if len(fields) == 0 {
                        continue
                }

                switch fields[0] {
                case "cpu":
                        // cpu user nice system idle iowait irq softirq steal guest guest_nice
                        if len(fields) > 1 {
                                m["user"], _ = strconv.ParseInt(fields[1], 10, 64)
                        }
                        if len(fields) > 2 {
                                m["nice"], _ = strconv.ParseInt(fields[2], 10, 64)
                        }
                        if len(fields) > 3 {
                                m["system"], _ = strconv.ParseInt(fields[3], 10, 64)
                        }
                        if len(fields) > 4 {
                                m["idle"], _ = strconv.ParseInt(fields[4], 10, 64)
                        }
                        if len(fields) > 5 {
                                m["iowait"], _ = strconv.ParseInt(fields[5], 10, 64)
                        }
                        if len(fields) > 6 {
                                m["irq"], _ = strconv.ParseInt(fields[6], 10, 64)
                        }
                        if len(fields) > 7 {
                                m["softirq"], _ = strconv.ParseInt(fields[7], 10, 64)
                        }
                        if len(fields) > 8 {
                                m["steal"], _ = strconv.ParseInt(fields[8], 10, 64)
                        }
                case "ctxt":
                        if len(fields) > 1 {
                                m["ctxt"], _ = strconv.ParseInt(fields[1], 10, 64)
                        }
                }
        }
        return m, ts
}

// parseLoadAvg reads the 1-minute load average from /proc/loadavg.
func parseLoadAvg() (float64, int64) {
        content, ts := exporter.readFile("/proc/loadavg")
        fields := strings.Fields(content)
        if len(fields) == 0 {
                return 0, ts
        }
        v, _ := strconv.ParseFloat(fields[0], 64)
        return v, ts
}

// getCPUFreq returns average CPU frequency in MHz.
// Tries sysfs first, falls back to /proc/cpuinfo.
func getCPUFreq() (float64, int64) {
        ts := nowMilli()

        // Try sysfs scaling_cur_freq (in kHz)
        pattern := "/sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq"
        matches, _ := filepath.Glob(pattern)

        if len(matches) > 0 {
                var sum int64
                var count int
                for _, p := range matches {
                        v, _ := exporter.readInt(p)
                        if v > 0 {
                                sum += v
                                count++
                        }
                }
                if count > 0 {
                        return float64(sum) / float64(count) / 1000.0, ts
                }
        }

        // Fallback to /proc/cpuinfo
        lines, ts := exporter.readLines("/proc/cpuinfo")
        for _, line := range lines {
                if strings.HasPrefix(line, "cpu MHz") {
                        idx := strings.Index(line, ":")
                        if idx >= 0 {
                                v, _ := strconv.ParseFloat(strings.TrimSpace(line[idx+1:]), 64)
                                return v, ts
                        }
                }
        }
        return 0, ts
}

func getNumCPU() int {
        // Count cpu directories in sysfs
        matches, _ := filepath.Glob("/sys/devices/system/cpu/cpu[0-9]*")
        if len(matches) > 0 {
                return len(matches)
        }
        return 1
}

func getCPUModel() string {
        lines, _ := exporter.readLines("/proc/cpuinfo")
        for _, line := range lines {
                if strings.HasPrefix(line, "model name") {
                        idx := strings.Index(line, ":")
                        if idx >= 0 {
                                return strings.TrimSpace(line[idx+1:])
                        }
                }
        }
        return "unknown"
}

func getKernelInfo() string {
        content, _ := exporter.readFile("/proc/version")
        return content
}

// getCPUCache reads cache info from sysfs.
// Returns map with keys like "L1d", "L1i", "L2", "L3" and values in bytes.
func getCPUCache() map[string]int64 {
        result := make(map[string]int64)
        seen := make(map[string]map[string]bool) // key -> shared_cpu_map -> seen

        pattern := "/sys/devices/system/cpu/cpu*/cache/index*"
        matches, _ := filepath.Glob(pattern)

        for _, dir := range matches {
                level, _ := exporter.readFile(filepath.Join(dir, "level"))
                ctype, _ := exporter.readFile(filepath.Join(dir, "type"))
                sizeStr, _ := exporter.readFile(filepath.Join(dir, "size"))
                cpuMap, _ := exporter.readFile(filepath.Join(dir, "shared_cpu_map"))

                if level == "" || sizeStr == "" {
                        continue
                }

                // Build cache key (L1d, L1i, L2, L3)
                suffix := ""
                switch ctype {
                case "Data":
                        suffix = "d"
                case "Instruction":
                        suffix = "i"
                }
                key := "L" + level + suffix

                // Parse size (e.g., "32K", "256K", "8192K")
                size := parseSize(sizeStr)

                // Deduplicate by shared_cpu_map
                if seen[key] == nil {
                        seen[key] = make(map[string]bool)
                }
                if !seen[key][cpuMap] {
                        seen[key][cpuMap] = true
                        result[key] += size
                }
        }
        return result
}

func parseSize(s string) int64 {
        s = strings.TrimSpace(s)
        mult := int64(1)
        if strings.HasSuffix(s, "K") {
                mult = 1024
                s = s[:len(s)-1]
        } else if strings.HasSuffix(s, "M") {
                mult = 1024 * 1024
                s = s[:len(s)-1]
        }
        v, _ := strconv.ParseInt(s, 10, 64)
        return v * mult
}

func nowMilli() int64 {
        return time.Now().UnixMilli()
}
package collectors

import (
        "regexp"
        "strconv"
        "strings"

        "github.com/inference-profiler"
)

// DiskMetrics contains VM-level disk I/O measurements.
type DiskMetrics struct {
        // Sector counts (1 sector = 512 bytes)
        SectorReads  exporter.Timed[int64] `json:"vDiskSectorReads"`
        SectorWrites exporter.Timed[int64] `json:"vDiskSectorWrites"`

        // Byte counts (derived from sectors)
        ReadBytes  exporter.Timed[int64] `json:"vDiskReadBytes"`
        WriteBytes exporter.Timed[int64] `json:"vDiskWriteBytes"`

        // Operation counts
        SuccessfulReads  exporter.Timed[int64] `json:"vDiskSuccessfulReads"`
        SuccessfulWrites exporter.Timed[int64] `json:"vDiskSuccessfulWrites"`
        MergedReads      exporter.Timed[int64] `json:"vDiskMergedReads"`
        MergedWrites     exporter.Timed[int64] `json:"vDiskMergedWrites"`

        // Timing (milliseconds)
        ReadTime       exporter.Timed[int64] `json:"vDiskReadTime"`
        WriteTime      exporter.Timed[int64] `json:"vDiskWriteTime"`
        IOTime         exporter.Timed[int64] `json:"vDiskIOTime"`
        WeightedIOTime exporter.Timed[int64] `json:"vDiskWeightedIOTime"`

        // Queue
        IOInProgress exporter.Timed[int64] `json:"vDiskIOInProgress"`
}

const sectorSize = 512

// diskPattern matches physical disk devices, excluding partitions and virtual devices.
// Matches: sda, hda, vda, xvda, nvme0n1, mmcblk0
// Excludes: sda1, loop0, ram0
var diskPattern = regexp.MustCompile(`^(sd[a-z]+|hd[a-z]+|vd[a-z]+|xvd[a-z]+|nvme\d+n\d+|mmcblk\d+)$`)

// CollectDisk gathers disk I/O metrics from /proc/diskstats.
// Aggregates across all physical disk devices.
func CollectDisk() DiskMetrics {
        lines, ts := exporter.readLines("/proc/diskstats")

        var (
                readCount, mergedReads, sectorReads, readTime     int64
                writeCount, mergedWrites, sectorWrites, writeTime int64
                ioInProgress, ioTime, weightedIOTime              int64
        )

        for _, line := range lines {
                fields := strings.Fields(line)
                if len(fields) < 14 {
                        continue
                }

                devName := fields[2]
                if !diskPattern.MatchString(devName) {
                        continue
                }

                // /proc/diskstats field positions (0-indexed):
                // 0: major, 1: minor, 2: device name
                // 3: reads completed, 4: reads merged, 5: sectors read, 6: read time ms
                // 7: writes completed, 8: writes merged, 9: sectors written, 10: write time ms
                // 11: I/O in progress, 12: I/O time ms, 13: weighted I/O time ms
                readCount += parseInt(fields[3])
                mergedReads += parseInt(fields[4])
                sectorReads += parseInt(fields[5])
                readTime += parseInt(fields[6])
                writeCount += parseInt(fields[7])
                mergedWrites += parseInt(fields[8])
                sectorWrites += parseInt(fields[9])
                writeTime += parseInt(fields[10])
                ioInProgress += parseInt(fields[11])
                ioTime += parseInt(fields[12])
                weightedIOTime += parseInt(fields[13])
        }

        return DiskMetrics{
                SectorReads:      exporter.TimedAt(sectorReads, ts),
                SectorWrites:     exporter.TimedAt(sectorWrites, ts),
                ReadBytes:        exporter.TimedAt(sectorReads*sectorSize, ts),
                WriteBytes:       exporter.TimedAt(sectorWrites*sectorSize, ts),
                SuccessfulReads:  exporter.TimedAt(readCount, ts),
                SuccessfulWrites: exporter.TimedAt(writeCount, ts),
                MergedReads:      exporter.TimedAt(mergedReads, ts),
                MergedWrites:     exporter.TimedAt(mergedWrites, ts),
                ReadTime:         exporter.TimedAt(readTime, ts),
                WriteTime:        exporter.TimedAt(writeTime, ts),
                IOTime:           exporter.TimedAt(ioTime, ts),
                WeightedIOTime:   exporter.TimedAt(weightedIOTime, ts),
                IOInProgress:     exporter.TimedAt(ioInProgress, ts),
        }
}

func parseInt(s string) int64 {
        v, _ := strconv.ParseInt(s, 10, 64)
        return v
}
package collectors

import (
        "os"
        "strings"
        "time"

        "github.com/inference-profiler/utils"
)

// Snapshot contains all dynamic metrics from a single collection cycle.
type Snapshot struct {
        Timestamp int64 `json:"timestamp"`

        CPU       CPUMetrics         `json:"cpu"`
        Memory    MemoryMetrics      `json:"mem"`
        Disk      DiskMetrics        `json:"disk"`
        Network   NetMetrics         `json:"net"`
        Container ContainerMetrics   `json:"containers"`
        NVIDIA    []GPUMetrics       `json:"nvidia,omitempty"`
        VLLM      VLLMMetrics        `json:"vllm,omitempty"`
        Processes *ProcessCollection `json:"processes,omitempty"`
}

// StaticInfo contains all static system information.
type StaticInfo struct {
        UUID   string     `json:"uuid"`
        VMID   string     `json:"vId"`
        Host   HostInfo   `json:"host"`
        NVIDIA *GPUStatic `json:"nvidia,omitempty"`
}

// HostInfo contains static host information.
type HostInfo struct {
        Hostname      string           `json:"hostname"`
        Kernel        string           `json:"kernel"`
        BootTime      int64            `json:"boot_time"`
        NumProcessors int              `json:"vNumProcessors"`
        CPUType       string           `json:"vCpuType"`
        CPUCache      map[string]int64 `json:"vCpuCache"`
        KernelInfo    string           `json:"vKernelInfo"`
        MemoryTotal   int64            `json:"vMemoryTotalBytes"`
        SwapTotal     int64            `json:"vSwapTotalBytes"`
}

// Manager coordinates all metric collectors.
type Manager struct {
        collectProcesses bool
        nvml             *NVMLCollector
}

// NewManager creates a new collector manager.
// collectProcesses enables per-process metric collection (expensive).
func NewManager(collectProcesses bool) *Manager {
        m := &Manager{
                collectProcesses: collectProcesses,
                nvml:             NewNVMLCollector(),
        }
        m.nvml.Init()
        return m
}

// Collect gathers all dynamic metrics.
func (m *Manager) Collect() Snapshot {
        s := Snapshot{
                Timestamp: time.Now().UnixMilli(),
                CPU:       CollectCPU(),
                Memory:    CollectMemory(),
                Disk:      CollectDisk(),
                Network:   CollectNet(),
                Container: CollectContainer(),
                NVIDIA:    m.nvml.Collect(),
                VLLM:      CollectVLLM(),
        }

        if m.collectProcesses {
                procs := CollectProcesses()
                s.Processes = &procs
        }

        return s
}

// GetStatic gathers all static system information.
func (m *Manager) GetStatic(sessionUUID string) StaticInfo {
        cpuStatic := CollectCPUStatic()
        memStatic := CollectMemoryStatic()

        hostname, _ := os.Hostname()
        uname, _ := utils.ReadFile("/proc/version")

        return StaticInfo{
                UUID: sessionUUID,
                VMID: getVMID(),
                Host: HostInfo{
                        Hostname:      hostname,
                        Kernel:        uname,
                        BootTime:      getBootTime(),
                        NumProcessors: cpuStatic.NumProcessors,
                        CPUType:       cpuStatic.Model,
                        CPUCache:      cpuStatic.Cache,
                        KernelInfo:    cpuStatic.KernelInfo,
                        MemoryTotal:   memStatic.TotalBytes,
                        SwapTotal:     memStatic.SwapTotalBytes,
                },
                NVIDIA: m.nvml.GetStatic(),
        }
}

// Close releases all collector resources.
func (m *Manager) Close() {
        if m.nvml != nil {
                m.nvml.Close()
        }
}

// getBootTime reads system boot time from /proc/stat.
func getBootTime() int64 {
        lines, _ := utils.ReadLines("/proc/stat")
        for _, line := range lines {
                if strings.HasPrefix(line, "btime ") {
                        fields := strings.Fields(line)
                        if len(fields) >= 2 {
                                v, _ := parseInt(fields[1]), int64(0)
                                return v
                        }
                }
        }
        return 0
}

// getVMID attempts to get VM/instance ID from various sources.
func getVMID() string {
        // Try DMI product UUID
        if id, _ := utils.ReadFile("/sys/class/dmi/id/product_uuid"); id != "" && id != "None" {
                return id
        }

        // Try machine ID as fallback
        if id, _ := utils.ReadFile("/etc/machine-id"); id != "" {
                return id
        }

        return "unavailable"
}
package collectors

import (
        "regexp"
        "strconv"

        "github.com/inference-profiler"
        "github.com/inference-profiler/utils"
)

// MemoryMetrics contains VM-level memory measurements.
// All sizes are in bytes.
type MemoryMetrics struct {
        // Physical memory
        Total   exporter.Timed[int64]   `json:"vMemoryTotal"`   // Total RAM installed
        Free    exporter.Timed[int64]   `json:"vMemoryFree"`    // Available memory
        Used    exporter.Timed[int64]   `json:"vMemoryUsed"`    // Actively used
        Buffers exporter.Timed[int64]   `json:"vMemoryBuffers"` // Kernel buffers
        Cached  exporter.Timed[int64]   `json:"vMemoryCached"`  // Page cache
        Percent exporter.Timed[float64] `json:"vMemoryPercent"` // Usage percentage

        // Swap space
        SwapTotal exporter.Timed[int64] `json:"vSwapTotal"` // Total swap
        SwapFree  exporter.Timed[int64] `json:"vSwapFree"`  // Unused swap
        SwapUsed  exporter.Timed[int64] `json:"vSwapUsed"`  // Used swap

        // Page faults
        PageFault      exporter.Timed[int64] `json:"vPgFault"`        // Minor page faults
        MajorPageFault exporter.Timed[int64] `json:"vMajorPageFault"` // Major (disk) faults
}

// MemoryStatic contains static memory information.
type MemoryStatic struct {
        TotalBytes     int64 `json:"vMemoryTotalBytes"` // Total RAM
        SwapTotalBytes int64 `json:"vSwapTotalBytes"`   // Total swap
}

var (
        pgFaultRE    = regexp.MustCompile(`pgfault\s+(\d+)`)
        pgMajFaultRE = regexp.MustCompile(`pgmajfault\s+(\d+)`)
)

// CollectMemory gathers memory metrics from /proc/meminfo and /proc/vmstat.
func CollectMemory() MemoryMetrics {
        info, ts := parseMemInfo()
        pgFault, pgMajFault, vmstatTS := parseVMStat()

        total := info["MemTotal"]
        freeRaw := info["MemFree"]
        buffers := info["Buffers"]
        cached := info["Cached"] + info["SReclaimable"]

        // Calculate available memory
        available := info["MemAvailable"]
        if available == 0 {
                available = freeRaw + buffers + cached
        }

        used := total - freeRaw - buffers - cached

        var percent float64
        if total > 0 {
                percent = float64(total-available) / float64(total) * 100
        }

        swapTotal := info["SwapTotal"]
        swapFree := info["SwapFree"]

        return MemoryMetrics{
                Total:          exporter.TimedAt(total, ts),
                Free:           exporter.TimedAt(available, ts),
                Used:           exporter.TimedAt(used, ts),
                Buffers:        exporter.TimedAt(buffers, ts),
                Cached:         exporter.TimedAt(cached, ts),
                Percent:        exporter.TimedAt(percent, ts),
                SwapTotal:      exporter.TimedAt(swapTotal, ts),
                SwapFree:       exporter.TimedAt(swapFree, ts),
                SwapUsed:       exporter.TimedAt(swapTotal-swapFree, ts),
                PageFault:      exporter.TimedAt(pgFault, vmstatTS),
                MajorPageFault: exporter.TimedAt(pgMajFault, vmstatTS),
        }
}

// CollectMemoryStatic gathers static memory info.
func CollectMemoryStatic() MemoryStatic {
        info, _ := parseMemInfo()
        return MemoryStatic{
                TotalBytes:     info["MemTotal"],
                SwapTotalBytes: info["SwapTotal"],
        }
}

// parseMemInfo parses /proc/meminfo into bytes.
func parseMemInfo() (map[string]int64, int64) {
        kv, ts := utils.parseKV("/proc/meminfo", ':')
        m := make(map[string]int64)
        for k, v := range kv {
                m[k] = utils.parseMemValue(v)
        }
        return m, ts
}

// parseVMStat extracts page fault counters from /proc/vmstat.
func parseVMStat() (pgFault, pgMajFault int64, ts int64) {
        content, ts := utils.readFile("/proc/vmstat")
        if content == "" {
                return 0, 0, ts
        }

        if m := pgFaultRE.FindStringSubmatch(content); len(m) > 1 {
                pgFault, _ = strconv.ParseInt(m[1], 10, 64)
        }
        if m := pgMajFaultRE.FindStringSubmatch(content); len(m) > 1 {
                pgMajFault, _ = strconv.ParseInt(m[1], 10, 64)
        }
        return pgFault, pgMajFault, ts
}
package collectors

import (
        "strconv"
        "strings"

        "github.com/inference-profiler"
        "github.com/inference-profiler/utils"
)

// NetMetrics contains VM-level network measurements.
// Aggregated across all non-loopback interfaces.
type NetMetrics struct {
        // Byte counters
        BytesRecvd exporter.Timed[int64] `json:"vNetworkBytesRecvd"`
        BytesSent  exporter.Timed[int64] `json:"vNetworkBytesSent"`

        // Packet counters
        PacketsRecvd exporter.Timed[int64] `json:"vNetworkPacketsRecvd"`
        PacketsSent  exporter.Timed[int64] `json:"vNetworkPacketsSent"`

        // Error counters
        ErrorsRecvd exporter.Timed[int64] `json:"vNetworkErrorsRecvd"`
        ErrorsSent  exporter.Timed[int64] `json:"vNetworkErrorsSent"`

        // Drop counters
        DropsRecvd exporter.Timed[int64] `json:"vNetworkDropsRecvd"`
        DropsSent  exporter.Timed[int64] `json:"vNetworkDropsSent"`
}

// CollectNet gathers network metrics from /proc/net/dev.
// Skips loopback interface.
func CollectNet() NetMetrics {
        lines, ts := utils.readLines("/proc/net/dev")

        var bytesRecv, packetsRecv, errsRecv, dropsRecv int64
        var bytesSent, packetsSent, errsSent, dropsSent int64

        // Skip first 2 header lines
        for i := 2; i < len(lines); i++ {
                line := lines[i]
                colonIdx := strings.Index(line, ":")
                if colonIdx < 0 {
                        continue
                }

                iface := strings.TrimSpace(line[:colonIdx])
                data := line[colonIdx+1:]

                // Skip loopback
                if iface == "lo" {
                        continue
                }

                fields := strings.Fields(data)
                if len(fields) < 16 {
                        continue
                }

                // /proc/net/dev columns after interface name:
                // Receive: bytes packets errs drop fifo frame compressed multicast
                // Transmit: bytes packets errs drop fifo colls carrier compressed
                bytesRecv += parseNetField(fields[0])
                packetsRecv += parseNetField(fields[1])
                errsRecv += parseNetField(fields[2])
                dropsRecv += parseNetField(fields[3])

                bytesSent += parseNetField(fields[8])
                packetsSent += parseNetField(fields[9])
                errsSent += parseNetField(fields[10])
                dropsSent += parseNetField(fields[11])
        }

        return NetMetrics{
                BytesRecvd:   exporter.TimedAt(bytesRecv, ts),
                BytesSent:    exporter.TimedAt(bytesSent, ts),
                PacketsRecvd: exporter.TimedAt(packetsRecv, ts),
                PacketsSent:  exporter.TimedAt(packetsSent, ts),
                ErrorsRecvd:  exporter.TimedAt(errsRecv, ts),
                ErrorsSent:   exporter.TimedAt(errsSent, ts),
                DropsRecvd:   exporter.TimedAt(dropsRecv, ts),
                DropsSent:    exporter.TimedAt(dropsSent, ts),
        }
}

func parseNetField(s string) int64 {
        v, _ := strconv.ParseInt(s, 10, 64)
        return v
}
package collectors

import (
        "fmt"
        "sync"

        "github.com/inference-profiler"
        "github.com/inference-profiler/utils"
)

// GPUMetrics contains per-GPU measurements from NVML.
type GPUMetrics struct {
        // Identification
        Index int `json:"gGpuIndex"`

        // Utilization (percent)
        UtilizationGPU exporter.Timed[int] `json:"gUtilizationGpu"`
        UtilizationMem exporter.Timed[int] `json:"gUtilizationMem"`

        // Memory (MB)
        MemoryTotalMB exporter.Timed[int64] `json:"gMemoryTotalMb"`
        MemoryUsedMB  exporter.Timed[int64] `json:"gMemoryUsedMb"`
        MemoryFreeMB  exporter.Timed[int64] `json:"gMemoryFreeMb"`
        BAR1UsedMB    exporter.Timed[int64] `json:"gBar1UsedMb"`
        BAR1FreeMB    exporter.Timed[int64] `json:"gBar1FreeMb"`

        // Thermal
        TemperatureC exporter.Timed[int] `json:"gTemperatureC"`
        FanSpeed     exporter.Timed[int] `json:"gFanSpeed"`

        // Power (watts)
        PowerDrawW  exporter.Timed[float64] `json:"gPowerDrawW"`
        PowerLimitW exporter.Timed[float64] `json:"gPowerLimitW"`

        // Clocks (MHz)
        ClockGraphicsMHz exporter.Timed[int] `json:"gClockGraphicsMhz"`
        ClockSMMHz       exporter.Timed[int] `json:"gClockSmMhz"`
        ClockMemMHz      exporter.Timed[int] `json:"gClockMemMhz"`

        // PCIe (KB/s)
        PCIeTxKBps exporter.Timed[int] `json:"gPcieTxKbps"`
        PCIeRxKBps exporter.Timed[int] `json:"gPcieRxKbps"`

        // State
        PerfState exporter.Timed[string] `json:"gPerfState"`

        // ECC errors
        ECCSingleBit exporter.Timed[int64] `json:"gEccSingleBitErrors"`
        ECCDoubleBit exporter.Timed[int64] `json:"gEccDoubleBitErrors"`

        // Processes
        ProcessCount int      `json:"gProcessCount"`
        Processes    []string `json:"gProcesses"` // "PID: name (VRAM MB)"
}

// GPUStatic contains static GPU information.
type GPUStatic struct {
        DriverVersion string          `json:"gDriverVersion"`
        CUDAVersion   int             `json:"gCudaVersion"`
        GPUs          []GPUStaticInfo `json:"gpus"`
}

// GPUStaticInfo contains static info for a single GPU.
type GPUStaticInfo struct {
        Name             string `json:"gName"`
        UUID             string `json:"gUuid"`
        TotalMemoryMB    int64  `json:"gTotalMemoryMb"`
        PCIBusID         string `json:"gPciBusId"`
        MaxGraphicsClock int    `json:"gMaxGraphicsClock"`
        MaxSMClock       int    `json:"gMaxSmClock"`
        MaxMemClock      int    `json:"gMaxMemClock"`
}

// NVMLCollector manages NVIDIA GPU metric collection.
// Uses go-nvml bindings (requires NVIDIA drivers).
type NVMLCollector struct {
        mu          sync.Mutex
        initialized bool
        available   bool
}

// NewNVMLCollector creates a new NVML collector.
// Call Init() before collecting metrics.
func NewNVMLCollector() *NVMLCollector {
        return &NVMLCollector{}
}

// Init initializes NVML. Safe to call multiple times.
func (c *NVMLCollector) Init() error {
        c.mu.Lock()
        defer c.mu.Unlock()

        if c.initialized {
                return nil
        }

        // NVML initialization happens through CGO bindings
        // This is a stub - actual implementation requires go-nvml
        c.initialized = true
        c.available = false // Will be set true if NVML loads successfully

        return nil
}

// Collect gathers metrics from all GPUs.
// Returns empty slice if NVML unavailable.
func (c *NVMLCollector) Collect() []GPUMetrics {
        c.mu.Lock()
        defer c.mu.Unlock()

        if !c.available {
                return nil
        }

        // Stub - actual implementation uses go-nvml
        return nil
}

// GetStatic returns static GPU information.
func (c *NVMLCollector) GetStatic() *GPUStatic {
        c.mu.Lock()
        defer c.mu.Unlock()

        if !c.available {
                return nil
        }

        // Stub - actual implementation uses go-nvml
        return nil
}

// Close shuts down NVML.
func (c *NVMLCollector) Close() {
        c.mu.Lock()
        defer c.mu.Unlock()

        if c.initialized {
                // nvml.Shutdown()
                c.initialized = false
                c.available = false
        }
}

// getProcessName reads the process name from /proc/[pid]/comm.
func getProcessName(pid int) string {
        content, _ := utils.readFile(fmt.Sprintf("/proc/%d/comm", pid))
        if content == "" {
                return "unknown"
        }
        return content
}

// Available returns true if NVML is available.
func (c *NVMLCollector) Available() bool {
        c.mu.Lock()
        defer c.mu.Unlock()
        return c.available
}
package collectors

import (
        "os"
        "path/filepath"
        "strconv"
        "strings"

        "github.com/inference-profiler"
        "github.com/inference-profiler/utils"
)

// ProcessMetrics contains per-process measurements.
type ProcessMetrics struct {
        // Identification
        PID     int    `json:"pId"`
        Name    string `json:"pName"`
        Cmdline string `json:"pCmdline"`

        // Threading
        NumThreads exporter.Timed[int64] `json:"pNumThreads"`

        // CPU time (centiseconds)
        CPUUserMode        exporter.Timed[int64] `json:"pCpuTimeUserMode"`
        CPUKernelMode      exporter.Timed[int64] `json:"pCpuTimeKernelMode"`
        ChildrenUserMode   exporter.Timed[int64] `json:"pChildrenUserMode"`
        ChildrenKernelMode exporter.Timed[int64] `json:"pChildrenKernelMode"`

        // Context switches
        VoluntaryCtxSwitches    exporter.Timed[int64] `json:"pVoluntaryContextSwitches"`
        NonvoluntaryCtxSwitches exporter.Timed[int64] `json:"pNonvoluntaryContextSwitches"`

        // I/O delays (centiseconds)
        BlockIODelays exporter.Timed[int64] `json:"pBlockIODelays"`

        // Memory (bytes)
        VirtualMemory   exporter.Timed[int64] `json:"pVirtualMemoryBytes"`
        ResidentSetSize exporter.Timed[int64] `json:"pResidentSetSize"`
}

// ProcessCollection contains all process metrics plus summary.
type ProcessCollection struct {
        NumProcesses int              `json:"pNumProcesses"`
        Processes    []ProcessMetrics `json:"processes"`
}

// CollectProcesses gathers metrics for all running processes.
// This can be expensive on systems with many processes.
func CollectProcesses() ProcessCollection {
        pattern := "/proc/[0-9]*"
        matches, err := filepath.Glob(pattern)
        if err != nil {
                return ProcessCollection{}
        }

        pageSize := int64(os.Getpagesize())
        var processes []ProcessMetrics

        for _, pidPath := range matches {
                pid, err := strconv.Atoi(filepath.Base(pidPath))
                if err != nil {
                        continue
                }

                proc := collectProcess(pidPath, pid, pageSize)
                if proc != nil {
                        processes = append(processes, *proc)
                }
        }

        return ProcessCollection{
                NumProcesses: len(processes),
                Processes:    processes,
        }
}

// collectProcess gathers metrics for a single process.
func collectProcess(pidPath string, pid int, pageSize int64) *ProcessMetrics {
        // Read /proc/[pid]/stat
        statData, statTS := utils.readFile(filepath.Join(pidPath, "stat"))
        if statData == "" {
                return nil
        }

        // Parse stat file - handle process names with parentheses
        // Format: pid (comm) state ppid pgrp session tty_nr tpgid flags ...
        rparenIdx := strings.LastIndex(statData, ")")
        if rparenIdx < 0 || rparenIdx+2 >= len(statData) {
                return nil
        }

        // Extract comm from between parentheses
        lparenIdx := strings.Index(statData, "(")
        var name string
        if lparenIdx >= 0 && rparenIdx > lparenIdx {
                name = statData[lparenIdx+1 : rparenIdx]
        }

        // Fields after ) - indexed from 0
        fields := strings.Fields(statData[rparenIdx+2:])
        if len(fields) < 40 {
                return nil
        }

        // Field indices (after comm):
        // 0: state, 1: ppid, 2: pgrp, ..., 11: utime, 12: stime, 13: cutime, 14: cstime
        // 17: num_threads, 20: vsize, 39: delayacct_blkio_ticks
        utime, _ := strconv.ParseInt(fields[11], 10, 64)
        stime, _ := strconv.ParseInt(fields[12], 10, 64)
        cutime, _ := strconv.ParseInt(fields[13], 10, 64)
        cstime, _ := strconv.ParseInt(fields[14], 10, 64)
        numThreads, _ := strconv.ParseInt(fields[17], 10, 64)
        vsize, _ := strconv.ParseInt(fields[20], 10, 64)
        blkioDelay, _ := strconv.ParseInt(fields[39], 10, 64)

        // Read /proc/[pid]/status for context switches
        status, statusTS := utils.parseKV(filepath.Join(pidPath, "status"), ':')
        volCtx, _ := strconv.ParseInt(status["voluntary_ctxt_switches"], 10, 64)
        nvolCtx, _ := strconv.ParseInt(status["nonvoluntary_ctxt_switches"], 10, 64)

        // Use name from status if available
        if statusName, ok := status["Name"]; ok && statusName != "" {
                name = statusName
        }

        // Read /proc/[pid]/statm for RSS
        statmData, statmTS := utils.readFile(filepath.Join(pidPath, "statm"))
        var rssPages int64
        if statmData != "" {
                statmFields := strings.Fields(statmData)
                if len(statmFields) >= 2 {
                        rssPages, _ = strconv.ParseInt(statmFields[1], 10, 64)
                }
        }

        // Read /proc/[pid]/cmdline
        cmdline, _ := utils.readFile(filepath.Join(pidPath, "cmdline"))
        cmdline = strings.ReplaceAll(cmdline, "\x00", " ")
        cmdline = strings.TrimSpace(cmdline)

        return &ProcessMetrics{
                PID:                     pid,
                Name:                    name,
                Cmdline:                 cmdline,
                NumThreads:              exporter.TimedAt(numThreads, statTS),
                CPUUserMode:             exporter.TimedAt(utime*jiffiesPerSec, statTS),
                CPUKernelMode:           exporter.TimedAt(stime*jiffiesPerSec, statTS),
                ChildrenUserMode:        exporter.TimedAt(cutime*jiffiesPerSec, statTS),
                ChildrenKernelMode:      exporter.TimedAt(cstime*jiffiesPerSec, statTS),
                VoluntaryCtxSwitches:    exporter.TimedAt(volCtx, statusTS),
                NonvoluntaryCtxSwitches: exporter.TimedAt(nvolCtx, statusTS),
                BlockIODelays:           exporter.TimedAt(blkioDelay*jiffiesPerSec, statTS),
                VirtualMemory:           exporter.TimedAt(vsize, statTS),
                ResidentSetSize:         exporter.TimedAt(rssPages*pageSize, statmTS),
        }
}
package collectors

import (
        "io"
        "net/http"
        "os"
        "regexp"
        "sort"
        "strconv"
        "strings"
        "time"
)

// VLLMMetrics contains vLLM inference engine measurements.
// Parsed from Prometheus text format at /metrics endpoint.
type VLLMMetrics struct {
        Timestamp int64 `json:"timestamp,omitempty"`

        // System state
        RequestsRunning  float64 `json:"system_requests_running,omitempty"`
        RequestsWaiting  float64 `json:"system_requests_waiting,omitempty"`
        EngineSleepState float64 `json:"system_engine_sleep_state,omitempty"`
        PreemptionsTotal float64 `json:"system_preemptions_total,omitempty"`

        // Cache utilization
        KVCacheUsagePercent    float64 `json:"cache_kv_usage_percent,omitempty"`
        PrefixCacheHits        float64 `json:"cache_prefix_hits,omitempty"`
        PrefixCacheQueries     float64 `json:"cache_prefix_queries,omitempty"`
        MultimodalCacheHits    float64 `json:"cache_multimodal_hits,omitempty"`
        MultimodalCacheQueries float64 `json:"cache_multimodal_queries,omitempty"`

        // Throughput counters
        RequestsFinished  float64 `json:"requests_finished_total,omitempty"`
        RequestsCorrupted float64 `json:"requests_corrupted_total,omitempty"`
        PromptTokens      float64 `json:"tokens_prompt_total,omitempty"`
        GenerationTokens  float64 `json:"tokens_generation_total,omitempty"`

        // Latency sums (for computing averages with counts)
        LatencyTTFTSum       float64 `json:"latency_ttft_s_sum,omitempty"`
        LatencyE2ESum        float64 `json:"latency_e2e_s_sum,omitempty"`
        LatencyQueueSum      float64 `json:"latency_queue_s_sum,omitempty"`
        LatencyInferenceSum  float64 `json:"latency_inference_s_sum,omitempty"`
        LatencyPrefillSum    float64 `json:"latency_prefill_s_sum,omitempty"`
        LatencyDecodeSum     float64 `json:"latency_decode_s_sum,omitempty"`
        LatencyInterTokenSum float64 `json:"latency_inter_token_s_sum,omitempty"`

        // Histograms stored as bucket->cumulative_count
        Histograms map[string]map[string]float64 `json:"histograms,omitempty"`

        // Config info (extracted from *_info metrics)
        Config map[string]interface{} `json:"config,omitempty"`
}

// vLLM metric name aliases for cleaner JSON output.
var vllmAliases = map[string]string{
        "num_requests_running":           "system_requests_running",
        "num_requests_waiting":           "system_requests_waiting",
        "engine_sleep_state":             "system_engine_sleep_state",
        "num_preemptions":                "system_preemptions_total",
        "kv_cache_usage_perc":            "cache_kv_usage_percent",
        "prefix_cache_hits":              "cache_prefix_hits",
        "prefix_cache_queries":           "cache_prefix_queries",
        "mm_cache_hits":                  "cache_multimodal_hits",
        "mm_cache_queries":               "cache_multimodal_queries",
        "request_success":                "requests_finished_total",
        "corrupted_requests":             "requests_corrupted_total",
        "prompt_tokens":                  "tokens_prompt_total",
        "generation_tokens":              "tokens_generation_total",
        "time_to_first_token_seconds":    "latency_ttft_s",
        "e2e_request_latency_seconds":    "latency_e2e_s",
        "request_queue_time_seconds":     "latency_queue_s",
        "request_inference_time_seconds": "latency_inference_s",
        "request_prefill_time_seconds":   "latency_prefill_s",
        "request_decode_time_seconds":    "latency_decode_s",
        "inter_token_latency_seconds":    "latency_inter_token_s",
}

// Labels to ignore (reduce noise).
var ignoredLabels = map[string]bool{
        "model_name": true, "model": true, "engine_id": true,
        "engine": true, "handler": true, "method": true,
}

// Prometheus line regex: metric{labels} value
var promLineRE = regexp.MustCompile(`^([a-zA-Z0-9_:]+)(?:\{(.+)\})?\s+([0-9\.eE\+\-]+|nan|inf|NaN|Inf)$`)

// CollectVLLM scrapes metrics from vLLM's Prometheus endpoint.
func CollectVLLM() VLLMMetrics {
        url := os.Getenv("VLLM_METRICS_URL")
        if url == "" {
                url = "http://localhost:8000/metrics"
        }

        var m VLLMMetrics
        ts := time.Now().UnixMilli()

        client := http.Client{Timeout: 500 * time.Millisecond}
        resp, err := client.Get(url)
        if err != nil {
                return m
        }
        defer resp.Body.Close()

        body, err := io.ReadAll(resp.Body)
        if err != nil {
                return m
        }

        m = parsePrometheus(string(body))
        if len(m.Histograms) > 0 || m.RequestsRunning > 0 || m.RequestsWaiting > 0 {
                m.Timestamp = ts
        }
        return m
}

// parsePrometheus parses Prometheus text format into VLLMMetrics.
func parsePrometheus(text string) VLLMMetrics {
        m := VLLMMetrics{
                Histograms: make(map[string]map[string]float64),
                Config:     make(map[string]interface{}),
        }

        // Temporary storage for histogram buckets
        histoBuckets := make(map[string][]bucketEntry)

        for _, line := range strings.Split(text, "\n") {
                line = strings.TrimSpace(line)
                if line == "" || strings.HasPrefix(line, "#") {
                        continue
                }

                match := promLineRE.FindStringSubmatch(line)
                if match == nil {
                        continue
                }

                name, labelStr, valStr := match[1], match[2], match[3]
                val := parsePromValue(valStr)

                // Parse and filter labels
                labels := parseLabels(labelStr)

                // Strip vllm: prefix and handle suffixes
                name = strings.TrimPrefix(name, "vllm:")
                isBucket := strings.HasSuffix(name, "_bucket")
                isSum := strings.HasSuffix(name, "_sum")
                isCount := strings.HasSuffix(name, "_count")
                isInfo := strings.HasSuffix(name, "_info")

                baseName := name
                if isBucket {
                        baseName = name[:len(name)-7]
                } else if isSum {
                        baseName = name[:len(name)-4]
                } else if isCount {
                        baseName = name[:len(name)-6]
                }

                // Get alias if exists
                cleanName := baseName
                if alias, ok := vllmAliases[baseName]; ok {
                        cleanName = alias
                }

                // Handle _info metrics -> extract to config
                if isInfo && len(labels) > 0 {
                        for k, v := range labels {
                                m.Config[cleanName+"_"+k] = tryParseNumber(v)
                        }
                        continue
                }

                // Handle histogram buckets
                if isBucket {
                        le, ok := labels["le"]
                        if !ok {
                                continue
                        }
                        delete(labels, "le")

                        // Build histogram key
                        histoKey := buildKey(cleanName, labels)
                        histoBuckets[histoKey] = append(histoBuckets[histoKey], bucketEntry{
                                le:    parseLe(le),
                                count: val,
                        })
                        continue
                }

                // Handle _sum and _count
                if isSum {
                        assignSum(&m, cleanName, val)
                        continue
                }

                if isCount {
                        // Store count metrics if needed
                        continue
                }

                // Handle standard metrics
                assignMetric(&m, cleanName, val, labels)
        }

        // Convert histogram buckets to sorted maps
        for key, buckets := range histoBuckets {
                sort.Slice(buckets, func(i, j int) bool {
                        return buckets[i].le < buckets[j].le
                })

                histo := make(map[string]float64)
                for _, b := range buckets {
                        leKey := "inf"
                        if b.le != posInf {
                                leKey = strconv.FormatFloat(b.le, 'f', -1, 64)
                        }
                        histo[leKey] = b.count
                }
                m.Histograms[key+"_histogram"] = histo
        }

        return m
}

type bucketEntry struct {
        le    float64
        count float64
}

const posInf = 1e308

func parsePromValue(s string) float64 {
        s = strings.ToLower(s)
        if s == "nan" {
                return 0
        }
        if s == "inf" || s == "+inf" {
                return posInf
        }
        if s == "-inf" {
                return -posInf
        }
        v, _ := strconv.ParseFloat(s, 64)
        return v
}

func parseLe(s string) float64 {
        s = strings.ToLower(s)
        if s == "+inf" || s == "inf" {
                return posInf
        }
        v, _ := strconv.ParseFloat(s, 64)
        return v
}

func parseLabels(s string) map[string]string {
        m := make(map[string]string)
        if s == "" {
                return m
        }

        for _, part := range strings.Split(s, ",") {
                idx := strings.Index(part, "=")
                if idx < 0 {
                        continue
                }
                k := strings.TrimSpace(part[:idx])
                v := strings.Trim(strings.TrimSpace(part[idx+1:]), `"`)

                if !ignoredLabels[k] {
                        m[k] = v
                }
        }
        return m
}

func buildKey(base string, labels map[string]string) string {
        if len(labels) == 0 {
                return base
        }

        var parts []string
        for k, v := range labels {
                parts = append(parts, k+"_"+v)
        }
        sort.Strings(parts)
        return base + "_" + strings.Join(parts, "_")
}

func tryParseNumber(s string) interface{} {
        if i, err := strconv.ParseInt(s, 10, 64); err == nil {
                return i
        }
        if f, err := strconv.ParseFloat(s, 64); err == nil {
                return f
        }
        return s
}

func assignSum(m *VLLMMetrics, name string, val float64) {
        switch name {
        case "latency_ttft_s":
                m.LatencyTTFTSum = val
        case "latency_e2e_s":
                m.LatencyE2ESum = val
        case "latency_queue_s":
                m.LatencyQueueSum = val
        case "latency_inference_s":
                m.LatencyInferenceSum = val
        case "latency_prefill_s":
                m.LatencyPrefillSum = val
        case "latency_decode_s":
                m.LatencyDecodeSum = val
        case "latency_inter_token_s":
                m.LatencyInterTokenSum = val
        }
}

func assignMetric(m *VLLMMetrics, name string, val float64, labels map[string]string) {
        switch name {
        case "system_requests_running":
                m.RequestsRunning = val
        case "system_requests_waiting":
                m.RequestsWaiting = val
        case "system_engine_sleep_state":
                m.EngineSleepState = val
        case "system_preemptions_total":
                m.PreemptionsTotal = val
        case "cache_kv_usage_percent":
                m.KVCacheUsagePercent = val
        case "cache_prefix_hits":
                m.PrefixCacheHits = val
        case "cache_prefix_queries":
                m.PrefixCacheQueries = val
        case "cache_multimodal_hits":
                m.MultimodalCacheHits = val
        case "cache_multimodal_queries":
                m.MultimodalCacheQueries = val
        case "requests_finished_total":
                m.RequestsFinished = val
        case "requests_corrupted_total":
                m.RequestsCorrupted = val
        case "tokens_prompt_total":
                m.PromptTokens = val
        case "tokens_generation_total":
                m.GenerationTokens = val
        }
}
// Package collector provides system metric collection from Linux procfs, sysfs, cgroups, and NVIDIA GPUs.
package utils

import "time"

// Timed wraps a metric value with its collection timestamp.
// Most metrics need timestamps for accurate rate calculations.
type Timed[T any] struct {
        Value T     `json:"value"`
        Time  int64 `json:"time"` // Unix milliseconds
}

// NewTimed creates a Timed value with the current timestamp.
func NewTimed[T any](v T) Timed[T] {
        return Timed[T]{Value: v, Time: time.Now().UnixMilli()}
}

// TimedAt creates a Timed value with a specific timestamp.
func TimedAt[T any](v T, t int64) Timed[T] {
        return Timed[T]{Value: v, Time: t}
}
package utils

import (
        "bufio"
        "os"
        "strconv"
        "strings"
        "time"
)

// ReadFile reads a file and returns its content with a timestamp.
// Returns empty string on error.
func ReadFile(path string) (string, int64) {
        ts := time.Now().UnixMilli()
        data, err := os.ReadFile(path)
        if err != nil {
                return "", ts
        }
        return strings.TrimSpace(string(data)), ts
}

// readInt reads a file containing a single integer.
// Returns 0 on error.
func readInt(path string) (int64, int64) {
        content, ts := ReadFile(path)
        if content == "" {
                return 0, ts
        }
        v, err := strconv.ParseInt(content, 10, 64)
        if err != nil {
                return 0, ts
        }
        return v, ts
}

// ReadLines reads a file into lines.
func ReadLines(path string) ([]string, int64) {
        ts := time.Now().UnixMilli()
        f, err := os.Open(path)
        if err != nil {
                return nil, ts
        }
        defer f.Close()

        var lines []string
        scanner := bufio.NewScanner(f)
        for scanner.Scan() {
                lines = append(lines, scanner.Text())
        }
        return lines, ts
}

// parseKV parses key-value files like /proc/meminfo.
// sep is the separator character (e.g., ':' or ' ').
func parseKV(path string, sep byte) (map[string]string, int64) {
        lines, ts := ReadLines(path)
        m := make(map[string]string)
        for _, line := range lines {
                idx := strings.IndexByte(line, sep)
                if idx < 0 {
                        continue
                }
                k := strings.TrimSpace(line[:idx])
                v := strings.TrimSpace(line[idx+1:])
                m[k] = v
        }
        return m, ts
}

// parseMemValue parses memory values like "1234 kB" to bytes.
func parseMemValue(s string) int64 {
        s = strings.TrimSuffix(s, " kB")
        v, _ := strconv.ParseInt(s, 10, 64)
        return v * 1024
}
// Package exporter handles metric output in JSON, CSV, and Parquet formats.
package utils

import (
        "encoding/csv"
        "encoding/json"
        "fmt"
        "os"
        "path/filepath"
        "sort"

        "github.com/inference-profiler/internal/collector"
)

// Exporter manages metric output files.
type Exporter struct {
        outputDir     string
        sessionUUID   string
        snapshotFiles []string
}

// New creates a new Exporter.
func New(outputDir, sessionUUID string) *Exporter {
        os.MkdirAll(outputDir, 0755)
        return &Exporter{
                outputDir:   outputDir,
                sessionUUID: sessionUUID,
        }
}

// SaveStatic writes static info to JSON.
func (e *Exporter) SaveStatic(info collector.StaticInfo) error {
        path := filepath.Join(e.outputDir, fmt.Sprintf("static_%s.json", e.sessionUUID))
        f, err := os.Create(path)
        if err != nil {
                return err
        }
        defer f.Close()

        enc := json.NewEncoder(f)
        enc.SetIndent("", "  ")
        return enc.Encode(info)
}

// SaveSnapshot writes a single metric snapshot to JSON.
func (e *Exporter) SaveSnapshot(s collector.Snapshot) error {
        filename := fmt.Sprintf("%s-%d.json", e.sessionUUID, s.Timestamp)
        path := filepath.Join(e.outputDir, filename)

        f, err := os.Create(path)
        if err != nil {
                return err
        }
        defer f.Close()

        if err := json.NewEncoder(f).Encode(s); err != nil {
                return err
        }

        e.snapshotFiles = append(e.snapshotFiles, path)
        return nil
}

// ProcessSession aggregates all snapshots into final output format.
func (e *Exporter) ProcessSession(format string) error {
        if len(e.snapshotFiles) == 0 {
                return nil
        }

        // Sort files by name (timestamp)
        sort.Strings(e.snapshotFiles)

        // Load all snapshots
        var records []map[string]interface{}
        for _, path := range e.snapshotFiles {
                data, err := os.ReadFile(path)
                if err != nil {
                        continue
                }

                var m map[string]interface{}
                if err := json.Unmarshal(data, &m); err != nil {
                        continue
                }

                flat := flatten(m, "")
                records = append(records, flat)
        }

        if len(records) == 0 {
                return nil
        }

        basePath := filepath.Join(e.outputDir, e.sessionUUID)

        switch format {
        case "csv":
                return e.writeCSV(basePath+".csv", records, ",")
        case "tsv":
                return e.writeCSV(basePath+".tsv", records, "\t")
        case "parquet":
                // Parquet requires additional dependencies (arrow)
                // Fall back to CSV with a note
                fmt.Println("Note: Parquet output requires Apache Arrow. Using CSV.")
                return e.writeCSV(basePath+".csv", records, ",")
        default:
                return e.writeCSV(basePath+".csv", records, ",")
        }
}

// writeCSV writes records to CSV/TSV.
func (e *Exporter) writeCSV(path string, records []map[string]interface{}, sep string) error {
        if len(records) == 0 {
                return nil
        }

        // Collect all keys
        keySet := make(map[string]bool)
        for _, r := range records {
                for k := range r {
                        keySet[k] = true
                }
        }

        // Sort keys for consistent column order
        var keys []string
        for k := range keySet {
                keys = append(keys, k)
        }
        sort.Strings(keys)

        f, err := os.Create(path)
        if err != nil {
                return err
        }
        defer f.Close()

        w := csv.NewWriter(f)
        if sep == "\t" {
                w.Comma = '\t'
        }

        // Header
        if err := w.Write(keys); err != nil {
                return err
        }

        // Rows
        for _, r := range records {
                row := make([]string, len(keys))
                for i, k := range keys {
                        if v, ok := r[k]; ok {
                                row[i] = fmt.Sprintf("%v", v)
                        }
                }
                if err := w.Write(row); err != nil {
                        return err
                }
        }

        w.Flush()
        return w.Error()
}

// flatten converts nested map to flat key-value pairs.
// Nested keys are joined with underscore.
func flatten(m map[string]interface{}, prefix string) map[string]interface{} {
        result := make(map[string]interface{})

        for k, v := range m {
                key := k
                if prefix != "" {
                        key = prefix + "_" + k
                }

                switch val := v.(type) {
                case map[string]interface{}:
                        for fk, fv := range flatten(val, key) {
                                result[fk] = fv
                        }
                case []interface{}:
                        // Convert arrays to JSON strings
                        data, _ := json.Marshal(val)
                        result[key] = string(data)
                default:
                        result[key] = val
                }
        }

        return result
}

~/src/InferenceProfiler
❯ tree
.
├── collectors
│   ├── container.go
│   ├── cpu.go
│   ├── disk.go
│   ├── manager.go
│   ├── mem.go
│   ├── net.go
│   ├── nvidia.go
│   ├── proc.go
│   └── vllm.go
├── generate_testdata.sh
├── go.mod
├── main.go
├── Makefile
├── README.md
└── utils
    ├── exporter.go
    ├── parse.go
    └── timed.go

3 directories, 17 files